{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> get evolving temperature for academic paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from time import perf_counter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from itertools import product, combinations, chain\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Domain:\n",
    "    '''\n",
    "    domain with one pionneering paper\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.G = nx.DiGraph()\n",
    "        self.pioneer_node = 0  # pionneering node id in G, not the original one\n",
    "        self.num_of_nodes = 0 \n",
    "        self.num_of_edges = 0\n",
    "        \n",
    "        self.skeleton_tree = nx.DiGraph()\n",
    "        self.node_node_reduction_index = None\n",
    "        self.node_network_reduction_index = None\n",
    "        self.node_node_average_step = 0\n",
    "        \n",
    "        self.average_temperature = 0\n",
    "        self.average_growth_temperature = 0\n",
    "        self.average_struct_temperature = 0\n",
    "        self.volume = 0  # int\n",
    "        self.mass = 0  # float\n",
    "        self.node_tree_entropy = None\n",
    "        self.node_temperature = None\n",
    "        self.evolving_until_yr = 0\n",
    "        self.birth_yr = 0\n",
    "        \n",
    "        self.von_neumann_entropy = 0\n",
    "        \n",
    "    def setBirthYear(self, yr):\n",
    "        self.birth_yr = yr\n",
    "        \n",
    "    def evolve(self, df, lead_paper_id, start_yr, step=1):\n",
    "        # extract reference for a year\n",
    "        df_t = df[(df['year']>= start_yr) & (df['year']< start_yr+step)][['paper_id','reference_id']]\n",
    "        G_t = nx.from_pandas_edgelist(df_t, source = 'reference_id', target = 'paper_id', create_using = nx.DiGraph)\n",
    "        self.G.add_nodes_from(G_t.nodes)\n",
    "        self.G.add_edges_from(G_t.edges)\n",
    "        \n",
    "        # add self-loop for pioneer paper (if no self-loop yet in G)\n",
    "        self.G.add_edge(lead_paper_id, lead_paper_id)\n",
    "\n",
    "        # initialize class attributes\n",
    "        self.pioneer_node = np.argwhere(np.array(self.G.nodes)==lead_paper_id).flatten()[0]\n",
    "        self.num_of_nodes = self.G.number_of_nodes()\n",
    "        self.num_of_edges = self.G.number_of_edges()\n",
    "        self.node_node_reduction_index = np.zeros((self.num_of_nodes, self.num_of_nodes))\n",
    "        self.node_network_reduction_index = np.empty(self.num_of_nodes)\n",
    "        self.node_tree_entropy = np.empty(self.num_of_nodes)\n",
    "        self.node_temperature = np.empty(self.num_of_nodes)\n",
    "        self.evolving_until_yr = min(start_yr+step-1, 2020)\n",
    "        \n",
    "        # clear last round's weight attribute\n",
    "        for (n1, n2, d) in self.G.edges(data=True):\n",
    "            d.clear()\n",
    "        \n",
    "        self.von_neumann_entropy = 0\n",
    "        self.average_temperature = 0\n",
    "        self.average_growth_temperature = 0\n",
    "        self.average_struct_temperature = 0\n",
    "        \n",
    "    def getVonNeumannEntropy(self):\n",
    "        '''\n",
    "        Compute G's von neumann entropy \n",
    "        '''\n",
    "        for c in sorted(nx.strongly_connected_components(self.G), key=len, reverse=True):\n",
    "            sc_node_num = len(c)\n",
    "            if sc_node_num>1:\n",
    "                sub_G = self.G.subgraph(c).copy()\n",
    "                # add weight attr \n",
    "                nx.set_edge_attributes(sub_G, 1,'weight')\n",
    "                # get res\n",
    "                res = sum([wgt**2 * sub_G.in_degree(u)/sub_G.in_degree(v)/sub_G.out_degree(u)**2 \\\n",
    "                           for (u,v,wgt) in sub_G.edges.data('weight')])  #combinations(c, 2):   \n",
    "                self.von_neumann_entropy += 1-1/sc_node_num - res/2/sc_node_num**2\n",
    "            else:\n",
    "                # strongly connected component containing 1 node\n",
    "                # von neumann entropy = 0\n",
    "                break\n",
    "        print(\"von neumann entropy\")\n",
    "        print(self.von_neumann_entropy)    \n",
    "    \n",
    "    def setNodeReductionIdx(self):\n",
    "        '''\n",
    "        Compute node-node and node-network reduction index\n",
    "        Output:\n",
    "            Reduction_idx: a 2-D array of size (# node number * # node number)\n",
    "        '''\n",
    "        node_embeddings = self.getNodeEmbedding()\n",
    "        # node distance in embedding space\n",
    "        sparse_distance_mtrx = sparse.csr_matrix(self.getNodeDistance(node_embeddings.A))  # matrix.A  convert from matrix to ndarray\n",
    "        # weighted sparse adj matrix \n",
    "        sparse_adjacency_mtrx  = nx.to_scipy_sparse_matrix(self.G)\n",
    "        sparse_weighted_adj_mtrx = sparse_adjacency_mtrx.multiply(sparse_distance_mtrx) # element wise multiplication\n",
    "        # maximal node-pair distance in embedding space\n",
    "        max_distance = sparse_weighted_adj_mtrx.max()\n",
    "        # build weighted graph from sparse adj matrix\n",
    "        weighted_G = nx.from_scipy_sparse_matrix(sparse_weighted_adj_mtrx, create_using = nx.DiGraph, edge_attribute='weight')\n",
    "        # average node pair shortest distance \n",
    "        shortest_paths = dict(nx.all_pairs_dijkstra_path(weighted_G, weight='weight'))\n",
    "        self.node_node_average_step = self.getAvgStep(shortest_paths)\n",
    "        \n",
    "        # node-node reduction index\n",
    "        wgts = nx.get_edge_attributes(weighted_G, 'weight')\n",
    "        for i,j in product(range(self.num_of_nodes),range(self.num_of_nodes)):  # i --> j, find j's predecessors\n",
    "            if i==j:\n",
    "                continue \n",
    "            # get all shortest paths from i to j's references     \n",
    "            paths = list([shortest_paths[i].get(pre_j, []) for pre_j in weighted_G.predecessors(j)])\n",
    "            for p in paths:\n",
    "                if not p:  # if p is an empty list\n",
    "                    self.node_node_reduction_index[i,j] += max_distance * self.node_node_average_step\n",
    "                if len(p)>1:  # len(p)==1, path to itself, self-loop, no reduction     \n",
    "                    self.node_node_reduction_index[i,j] += np.sum([wgts[(p[i],p[i+1])] for i in range(len(p)-1)]) \n",
    "        \n",
    "        # add edge weight\n",
    "        mapping = {i:u for i,u in enumerate(self.G.nodes)}\n",
    "        nx.relabel_nodes(weighted_G, mapping, copy = False)\n",
    "        self.G = weighted_G\n",
    "        \n",
    "        # node-network reduction index\n",
    "        self.node_network_reduction_index = self.node_node_reduction_index.T @ np.ones((self.num_of_nodes,1))\n",
    "    \n",
    "    def buildSkeletonTree(self):\n",
    "        '''\n",
    "        build domain skeleton tree by trimming domain graph\n",
    "       \n",
    "        '''\n",
    "        # skeleton tree\n",
    "        T = deepcopy(self.G)\n",
    "        \n",
    "        ### Step 1\n",
    "        # detect loops in T\n",
    "        # cut an edge whose extremities have the biggest difference in reduction index \n",
    "        # keep graph connectivity \n",
    "        for i, src in enumerate(list(T.nodes)):\n",
    "            for target in list(T.nodes)[i+1:]: # src != target\n",
    "                if nx.has_path(T, src, target) and nx.has_path(T, target, src):\n",
    "                    has_loop = True\n",
    "                    while has_loop:\n",
    "                        try:\n",
    "                            loop = nx.shortest_path(T, source=src, target=target)[:-1] + \\\n",
    "                                   nx.shortest_path(T, source=target, target=src)\n",
    "                            self.cutEdgeInLoop(T, loop)\n",
    "                        except:\n",
    "                            has_loop = False\n",
    "\n",
    "        ### Step 2\n",
    "        # leave only one predecessor/reference for each paper\n",
    "        # remove directed edges\n",
    "\n",
    "        domain_nodes = T.nodes\n",
    "        for i,n in enumerate(domain_nodes):\n",
    "            pre_n = list(T.predecessors(n))\n",
    "            pre_n_idx = [np.argwhere(np.array(domain_nodes)==j).flatten()[0] for j in pre_n]\n",
    "            self_network_reduction_idx = self.node_network_reduction_index[i]\n",
    "            if len(pre_n)>1:\n",
    "                delta_reduction_idx = np.array([abs(self.node_network_reduction_index[j] -\n",
    "                                                    self_network_reduction_idx) for j in pre_n_idx])\n",
    "                reference_to_keep = pre_n.pop(np.argmin(delta_reduction_idx))      \n",
    "                for src in pre_n:\n",
    "                    T.remove_edge(src, n)          \n",
    "                    \n",
    "        self.skeleton_tree = T   \n",
    "        \n",
    "    def setNodeTreeEntropy(self):\n",
    "        '''\n",
    "        Compute tree entropy based on domain skeleton tree\n",
    "        Input:\n",
    "            T: nx.graph.DiGraph, skeleton tree\n",
    "        Output:\n",
    "            T: nx.graph.DiGraph, same skeleton tree with tree entropy added as a node attribute\n",
    "        '''\n",
    "        T = self.skeleton_tree\n",
    "        m = T.number_of_edges()\n",
    "        node_set = set(T.nodes)\n",
    "    \n",
    "        for i,n in enumerate(T.nodes):\n",
    "            if i==self.pioneer_node:\n",
    "              #  T.nodes[n]['tree_entropy'] = 0  # root entropy is always 0\n",
    "                self.node_tree_entropy[i] = 0\n",
    "            else:    \n",
    "                A_set = self.getSubTreeNodes([n])\n",
    "             #   B_set = node_set.difference(A_set)\n",
    "             #   cut_size = nx.cut_size(T, A_set, B_set) + nx.cut_size(T, B_set, A_set)\n",
    "                n_parents = list(T.predecessors(n))\n",
    "                sub_parent_T_nodes  = self.getSubTreeNodes(n_parents)\n",
    "                sub_T_volume = max(nx.volume(T, list(A_set), weight = None),1)  # sub_T_nodes\n",
    "            #    sub_parent_T_volume = max(nx.volume(T, list(sub_parent_T_nodes), weight = None),1)\n",
    "            #    self.node_tree_entropy[i] = -cut_size/(2*m)*np.log(sub_T_volume/sub_parent_T_volume)\n",
    "                if sub_parent_T_nodes:\n",
    "                    self.node_tree_entropy[i] = -sub_T_volume/(2*m)*np.log(len(A_set)/len(sub_parent_T_nodes))\n",
    "                else:\n",
    "                    self.node_tree_entropy[i] = 0  # isolated node\n",
    "                \n",
    "    def setStructTemperature(self, T):\n",
    "        self.average_struct_temperature = T\n",
    "    \n",
    "    def getAvgTemperature(self, is_initial = True, is_big_graph = True, old_avg_temperature = 0, old_V = 0, old_N = 0):\n",
    "        '''\n",
    "        Compute volume, mass and average temperature based on domain skeleton tree\n",
    "        Input: \n",
    "            is_initial: boolean, whether time stamp = 0\n",
    "            old_avg_temperature: float, average growth temperature for the last time stamp\n",
    "            old_V: int, volume of the last time stamp\n",
    "            old_N: float, mass of the last time stamp       \n",
    "        '''\n",
    "        ###### get average growth temperature \n",
    "        Tree = self.skeleton_tree\n",
    "        # volume\n",
    "        self.volume = self.num_of_nodes\n",
    "        # rescale node-node reduction index\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_node_reduction_index = scaler.fit_transform(self.node_node_reduction_index)\n",
    "        # mass\n",
    "        tree_adj = nx.to_scipy_sparse_matrix(Tree).todense()\n",
    "        tree_adj = np.where(tree_adj == 0,tree_adj, 1)\n",
    "        self.mass = self.num_of_nodes - np.sum(np.multiply(scaled_node_reduction_index, tree_adj))\n",
    "        # scaling coef\n",
    "        coef = 10 if is_big_graph else 100\n",
    "        if is_initial:\n",
    "            # entropy \n",
    "            S = np.sum(self.node_tree_entropy)\n",
    "            # set default constant\n",
    "            R = 8\n",
    "            c = 1 \n",
    "            self.average_growth_temperature =  coef * np.exp(S/(c*self.mass)) * np.float_power(self.mass/self.volume,R/c)\n",
    "        else:\n",
    "            self.average_growth_temperature = old_avg_temperature * (self.volume/old_V) * (old_N/self.mass)\n",
    "        print(\"volume:{}, mass:{}, T_growth:{}\".format(self.volume, self.mass, self.average_growth_temperature))  \n",
    "        \n",
    "        ###### get average temperature\n",
    "        self.average_temperature = self.average_growth_temperature + abs(self.average_struct_temperature)\n",
    "            \n",
    "    \n",
    "    def spreadTemperature(self, former_population = 0):\n",
    "        # get inactive nodes \n",
    "        coldest_nodes = self.getInactiveNodes(former_population)\n",
    "            \n",
    "        # add distance attribute to domain reference graph\n",
    "        scaler = MinMaxScaler(feature_range = (0.5,1.5))\n",
    "        scaled_node_node_reduction_idx = scaler.fit_transform(self.node_node_reduction_index)\n",
    "        node_list = list(self.G.nodes)\n",
    "        for u,v in self.G.edges:\n",
    "            self.G.edges[u,v]['distance'] = scaled_node_node_reduction_idx[node_list.index(u)][node_list.index(v)] \n",
    "\n",
    "        # get node temperature     \n",
    "        self.node_temperature = self.diffuseHeat(self.pioneer_node, coldest_nodes, int(self.node_node_average_step))   \n",
    "        \n",
    "                        \n",
    "    ########## auxiliary functions ##########\n",
    "    def getNodeEmbedding(self):\n",
    "\n",
    "        sparse_adjacency_mtrx  = nx.to_scipy_sparse_matrix(self.G)\n",
    "        sparse_degree_mtrx = np.diagflat(sparse_adjacency_mtrx.T @ np.ones((sparse_adjacency_mtrx.shape[0],1), dtype=int))\n",
    "        # Laplacian matrix \n",
    "        L = sparse_degree_mtrx - sparse_adjacency_mtrx.T\n",
    "        # regular Laplacian matrix\n",
    "        L_regular = np.sqrt(sparse_degree_mtrx) @ L @ np.sqrt(sparse_degree_mtrx)       \n",
    "        # node embedding (projected dimension = # node number)\n",
    "        _, eigvecs = np.linalg.eig(L_regular)\n",
    "        return eigvecs\n",
    "    \n",
    "    def getNodeDistance(self, M):\n",
    "        '''\n",
    "        Create distance matrix in embedding space \n",
    "        Extract node-pair distance for the graph\n",
    "        Input: \n",
    "            M: 2-D ndarray, eigenvectors of the regular Laplacian matrix, each row is a vector\n",
    "        Output:\n",
    "            D: 2-D ndarray, distance matrix of the graph\n",
    "        '''\n",
    "        N = M.shape[0]\n",
    "        D = np.empty(M.shape)\n",
    "        for i in range(N):\n",
    "            for j in range(i, N):\n",
    "                d = np.linalg.norm(M[i] - M[j]) # 2-norm\n",
    "                D[i,j], D[j,i] = d, d\n",
    "        return D \n",
    "                        \n",
    "    def getAvgStep(self, paths):\n",
    "        '''\n",
    "        Input: \n",
    "            paths: A dictionary of shortest paths dictionary\n",
    "        Output: \n",
    "            average shortest path length\n",
    "        '''\n",
    "        total_step = 0\n",
    "        path_counter = 0                        \n",
    "        for path_dict in paths.values():\n",
    "            steps = [len(p)-1 for p in path_dict.values()]\n",
    "            total_step += np.sum(steps)\n",
    "            path_counter += len(path_dict)-1\n",
    "        return total_step/path_counter               \n",
    "    \n",
    "    def cutEdgeInLoop(self, T, loop):\n",
    "        '''\n",
    "        cut an edge in a loop in domain skeleton tree T\n",
    "        Input:\n",
    "            T: networkx.graph.DiGraph  unweighted/weighted directed graph\n",
    "            loop: list representing a loop\n",
    "        Output:\n",
    "            None. T is already modified (dict object is changeable) \n",
    "        '''\n",
    "        nodes = np.array(T.nodes)\n",
    "        is_cut = False\n",
    "        edges_to_cut = dict([((loop[i], loop[i+1]), \n",
    "                              abs(self.node_network_reduction_index[i+1] - self.node_network_reduction_index[i])) \n",
    "                             for i in range(len(loop)-1)])\n",
    "        edges_to_cut = sorted(edges_to_cut.items(), key = lambda x: x[1], reverse=True) # sort by network reduction index \n",
    "        for edge,val in edges_to_cut:\n",
    "            if len(list(T.predecessors(edge[1]))) > 1:\n",
    "                T.remove_edge(edge[0], edge[1])\n",
    "                is_cut = True\n",
    "        if not is_cut:\n",
    "            T.remove_edge(edges_to_cut[0][0][0], edges_to_cut[0][0][1])\n",
    "                    \n",
    "    def getSubTreeNodes(self, parents):\n",
    "        '''\n",
    "        Find all the children of node n in domain skeleton tree, BFS search\n",
    "        Input:\n",
    "            parents: list of int, root nodes' ids\n",
    "        Output:\n",
    "            sub_T_nodes: set of int, all child nodes of parents and parents themselves\n",
    "        '''\n",
    "        sub_T_nodes = set()\n",
    "        child_nodes_to_parse = parents\n",
    "        while child_nodes_to_parse:\n",
    "            p = child_nodes_to_parse.pop(0)\n",
    "            sub_T_nodes.add(p)\n",
    "            child_nodes_to_parse.extend(list(self.skeleton_tree.successors(p))) # p has direct children\n",
    "        return sub_T_nodes\n",
    "    \n",
    "    def getInactiveNodes(self, former_population = 0):\n",
    "        '''\n",
    "        Input:\n",
    "            former_population: int, node number by the end of last time stamp\n",
    "        Output:\n",
    "            inactive_leaves: list, inactive node ids\n",
    "        '''\n",
    "        inactive_leaves = list()\n",
    "        for i,n in enumerate(self.G.nodes):\n",
    "            children = list(self.G.successors(n))\n",
    "            if not children:\n",
    "                inactive_leaves.append(i) \n",
    "            elif i < former_population and max(children)<former_population:\n",
    "                inactive_leaves.append(i)\n",
    "        return inactive_leaves\n",
    "    \n",
    "    def diffuseHeat(self, hottest_nodes, coldest_nodes, num_of_round):\n",
    "        #   diffuseHeat(self.pioneer_node, coldest_nodes, N = int(self.node_node_average_step))\n",
    "        '''\n",
    "        Compute heat diffusion over a skeleton tree\n",
    "        Input:\n",
    "            G: nx.graph.DiGraph,  loopless graph with node attribute 'tree_entropy'\n",
    "            hottest_nodes: list of int, nodes at temperature 1\n",
    "            coldest_nodes: list of int, nodes at temperature 0\n",
    "            num_of_round: int, number of steps    \n",
    "        Output: \n",
    "            Temperatures: ndarray, node temperature list after N steps \n",
    "        '''    \n",
    "       \n",
    "        adjacency = nx.to_scipy_sparse_matrix(self.G, weight = 'distance').T   \n",
    "        n = adjacency.shape[0]\n",
    "        Temperatures = 0.5 * np.ones(n, float)\n",
    "        sources = np.array(hottest_nodes)  \n",
    "        targets = np.array(coldest_nodes)\n",
    "\n",
    "        # fix source and target temperature\n",
    "        Temperatures[sources] = 1 # red\n",
    "        Temperatures[targets] = 0  # blue\n",
    "\n",
    "        # compute transition matrix\n",
    "        wgts = adjacency.dot(np.ones(n))\n",
    "        inverse_weight_matrix = sparse.diags(1 / wgts, format='csr')\n",
    "        P = inverse_weight_matrix.dot(adjacency)\n",
    "\n",
    "        \n",
    "        # heat diffusion \n",
    "        Temperatures = P.T.dot(Temperatures)\n",
    "        Temperatures = (Temperatures - min(Temperatures))/(max(Temperatures) - min(Temperatures))\n",
    "        Temperatures[sources] = 1   \n",
    "        Temperatures[targets] = 0\n",
    "        for i in range(num_of_round):\n",
    "            Temperatures = P.dot(Temperatures)   \n",
    "            # fix source and target temperature\n",
    "            Temperatures[sources] = 1   \n",
    "            Temperatures[targets] = 0    \n",
    "\n",
    "        # rescale temperature    \n",
    "        mean_T = np.mean(Temperatures)    \n",
    "        Temperatures *= self.average_temperature/mean_T    \n",
    "        return Temperatures\n",
    "    \n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $T_{struct}^t$ ---- shrink $G^{t+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_von_neumann_E_shrinked(prev_G, G, node_df):\n",
    "    '''\n",
    "    shrink G to a graph induced by nodes in prev_G\n",
    "    get von neumann entropy on the shrinked graph\n",
    "    Input:\n",
    "        prev_G: nx.DiGraph\n",
    "        G: nx.DiGraph\n",
    "        node_df: pandas DataFrame, columns = ['paper_id','year']\n",
    "    Output:\n",
    "        E: von neumann entropy of the graph shrinked from G\n",
    "    '''\n",
    "    \n",
    "    if not prev_G.number_of_nodes():\n",
    "        return 0,0\n",
    "    \n",
    "    node_df = node_df.set_index('paper_id')\n",
    "    new_edge_wgt_sum = 0\n",
    "    # shrink network\n",
    "    nx.set_edge_attributes(G, 1,'weight')\n",
    "    nodes_to_rm = set(G.nodes).difference(set(prev_G.nodes))\n",
    "    for n in nodes_to_rm:\n",
    "        parents_n = set(G.predecessors(n))\n",
    "        if len(parents_n) == 1:\n",
    "            for c in G.successors(n):\n",
    "                G.add_edge(next(iter(parents_n)), c, weight = G[n][c]['weight']/2) \n",
    "            G.remove_node(n)\n",
    "        else:\n",
    "            # more than 1 parent\n",
    "            # find all youngest ancestor nodes in prev_G\n",
    "            # add virtual edges between them, weight = 1/# youngest ancestor nodes\n",
    "            ancestors_n = parents_n\n",
    "            wgt_shared = sum([G[p][n]['weight'] for p in ancestors_n])\n",
    "            tmp = ancestors_n.intersection(nodes_to_rm)\n",
    "            while tmp:\n",
    "                tmp_ancestors = []\n",
    "                tmp_ancestors.extend([list(G.predecessors(k)) for k in tmp])\n",
    "                tmp_ancestors = list(chain.from_iterable(tmp_ancestors))  # unlist nested list\n",
    "                ancestors_n.union(set(tuple(tmp_ancestors)))\n",
    "                ancestors_n -= tmp # set difference\n",
    "                tmp = ancestors_n.intersection(nodes_to_rm)\n",
    "            num_of_ancestors = len(ancestors_n)\n",
    "            if num_of_ancestors > 1:\n",
    "                # add edge\n",
    "                ancestors_dict = dict([(i, node_df.at[i, 'year']) for i in ancestors_n])\n",
    "            #    ancestors_dict = sorted(ancestors_dict.items() ,  key=lambda x: x[1])\n",
    "                for u_dict,v_dict in combinations(ancestors_dict.items(),2):\n",
    "                    if not prev_G.has_edge(u_dict[0], v_dict[0]) and not prev_G.has_edge(u_dict[0], v_dict[0]):\n",
    "                        if not G.has_edge(u_dict[0], v_dict[0]) and not G.has_edge(v_dict[0], u_dict[0]): # 取第一条边\n",
    "                            if u_dict[1] < v_dict[1]: \n",
    "                                G.add_edge(u_dict[0], v_dict[0], weight = 2*wgt_shared/num_of_ancestors/(num_of_ancestors-1))\n",
    "                            elif u_dict[1] > v_dict[1]:\n",
    "                                G.add_edge(v_dict[0], u_dict[0], weight = 2*wgt_shared/num_of_ancestors/(num_of_ancestors-1))   \n",
    "                            else: # paper on same year, bidirectional edges\n",
    "                                G.add_edge(u_dict[0], v_dict[0], weight = wgt_shared/num_of_ancestors/(num_of_ancestors-1))\n",
    "                                G.add_edge(v_dict[0], u_dict[0], weight = wgt_shared/num_of_ancestors/(num_of_ancestors-1))\n",
    "                            new_edge_wgt_sum += 2*wgt_shared/num_of_ancestors/(num_of_ancestors-1)    \n",
    "                G.remove_node(n)\n",
    "            \n",
    "     # get entropy\n",
    "    E = 0\n",
    "    for c in sorted(nx.strongly_connected_components(G), key=len, reverse=True):\n",
    "        sc_node_num = len(c)\n",
    "        if sc_node_num>1:\n",
    "            sub_G = G.subgraph(c).copy()\n",
    "            # get res\n",
    "            res = sum([wgt**2 * sub_G.in_degree(u)/sub_G.in_degree(v)/sub_G.out_degree(u)**2 \\\n",
    "                       for (u,v,wgt) in sub_G.edges.data('weight')])  #combinations(c, 2):   \n",
    "            E += 1-1/sc_node_num - res/2/sc_node_num**2\n",
    "            for u,v in combinations(sub_G.nodes,2):\n",
    "                if sub_G.has_edge(u,v) and sub_G.has_edge(v,u):\n",
    "                    E -= sub_G[u][v]['weight']*sub_G[v][u]['weight']/sub_G.in_degree(v)/sub_G.out_degree(u)\n",
    "        else:\n",
    "            # strongly connected component containing 1 node\n",
    "            # von neumann entropy = 0\n",
    "            break\n",
    "    return E, new_edge_wgt_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8777697</td>\n",
       "      <td>99188113</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>498094871</td>\n",
       "      <td>99188113</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>352699142</td>\n",
       "      <td>99188113</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39453343</td>\n",
       "      <td>99188113</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>470391866</td>\n",
       "      <td>99188113</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    paper_id  reference_id  year\n",
       "0    8777697      99188113  1995\n",
       "1  498094871      99188113  1995\n",
       "2  352699142      99188113  1995\n",
       "3   39453343      99188113  1995\n",
       "4  470391866      99188113  1995"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_df = pd.read_csv(r'99188113domain_reference.csv')\n",
    "ref_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>352699142</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47465484</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34702267</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39453343</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>498094871</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    paper_id  year\n",
       "0  352699142  1993\n",
       "1   47465484  1993\n",
       "2   34702267  1993\n",
       "3   39453343  1994\n",
       "4  498094871  1994"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_df = pd.read_csv(r'99188113domain_paper.csv')\n",
    "paper_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run single-domain T evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEvolvingTemperature(ref_df, paper_df, lead_paper_id, evolve_step=1):\n",
    "    '''\n",
    "    Compute evolving node temperature based on mainly domain skeleton tree and node tree entropy\n",
    "    Visualise every evolve_step-year\n",
    "    Input: \n",
    "        ref_df: pandas Dataframe, columns = ['paper_id','reference_id','year']\n",
    "        paper_df:  pandas Dataframe, columns = ['paper_id','year']\n",
    "        lead_paper_id: int, original id of the pionneering work\n",
    "        evolve_step: interval between 2 visualization, unit: year \n",
    "    Output:\n",
    "        None\n",
    "    '''\n",
    "    domain = Domain()\n",
    "    start_year = ref_df['year'].min()\n",
    "    end_year = ref_df['year'].max()\n",
    "    T = int((end_year - start_year)/evolve_step)\n",
    "    delta = (end_year - start_year)%evolve_step \n",
    "    domain.setBirthYear(start_year)\n",
    "    \n",
    "    # record network size and average temperature for visualization\n",
    "    yr_stamps = list()\n",
    "    yr_node_number = list()\n",
    "    yr_edge_number = list()\n",
    "    yr_mass = list()\n",
    "    yr_volume = list()\n",
    "    yr_avg_growth_temperatures = list()\n",
    "    \n",
    "    von_neumann_entropies = list()\n",
    "    von_neumann_entropies_shrink = list()\n",
    "    yr_avg_struct_temperatures = list()\n",
    "    \n",
    "    is_big_graph = True if paper_df.shape[0]>5000 else False\n",
    "    \n",
    "    for t in range(T+1):\n",
    "        \n",
    "        print('round',t)\n",
    "        t3 = perf_counter()\n",
    "        \n",
    "        prev_G = deepcopy(domain.G)\n",
    "        \n",
    "        t1 = perf_counter()\n",
    "        domain.evolve(ref_df, lead_paper_id, start_year+delta+t*evolve_step, evolve_step)\n",
    "        print('Evolve domain elapsed time: {}s'.format(perf_counter() - t1))\n",
    "        \n",
    "        if t>=1:\n",
    "            # get equivalent shrinked network, remove all new nodes, add edges between old nodes\n",
    "            curr_G = deepcopy(domain.G)\n",
    "            H, delta_edge_sum = get_von_neumann_E_shrinked(prev_G, curr_G, paper_df)\n",
    "            H_prev = von_neumann_entropies[-1]\n",
    "            try:\n",
    "                struct_Temperature = delta_edge_sum/(H - H_prev) if delta_edge_sum else 0\n",
    "            except: # float division by 0 error\n",
    "                struct_Temperature = 10*delta_edge_sum\n",
    "            avg_struct_T = struct_Temperature/domain.num_of_nodes \n",
    "            domain.setStructTemperature(avg_struct_T)\n",
    "            print('old E: {o}, new_E: {n}, struct_T: {T}'.format(o=H_prev,n=H,T= avg_struct_T))\n",
    "    \n",
    "            von_neumann_entropies_shrink.append(H)\n",
    "            yr_avg_struct_temperatures.append(avg_struct_T)\n",
    "        else:\n",
    "            # first round, no struct change\n",
    "            yr_avg_struct_temperatures.append(0)\n",
    "            domain.setStructTemperature(0)\n",
    "            \n",
    "        domain.getVonNeumannEntropy()\n",
    "        von_neumann_entropies.append(domain.von_neumann_entropy)\n",
    "        \n",
    "        \n",
    "        t1 = perf_counter()\n",
    "        domain.setNodeReductionIdx()\n",
    "        print('Get node reduction index elapsed time: {}s'.format(perf_counter() - t1))\n",
    "        \n",
    "       \n",
    "        t1 = perf_counter()\n",
    "        domain.buildSkeletonTree()\n",
    "        print(\"Build skeleton tree elapsed time: {}s\".format(perf_counter() - t1))\n",
    "        \n",
    "        \n",
    "        ## compute tree entropy\n",
    "        t1 = perf_counter()    \n",
    "        domain.setNodeTreeEntropy()\n",
    "        print(\"Compute tree entropy elapsed time: {}s\".format(perf_counter() - t1))\n",
    " \n",
    "  \n",
    "        ## compute domain average temperature and node temperature\n",
    "        t1 = perf_counter()\n",
    "        if t == 0:    \n",
    "            domain.getAvgTemperature(is_initial = True, is_big_graph = is_big_graph)\n",
    "            domain.spreadTemperature(former_population = 0)\n",
    "        else:    \n",
    "            domain.getAvgTemperature(is_initial = False, is_big_graph = is_big_graph,\n",
    "                                                         old_avg_temperature = yr_avg_growth_temperatures[-1],\n",
    "                                                         old_V = yr_volume[-1],\n",
    "                                                         old_N = yr_mass[-1])\n",
    "            domain.spreadTemperature(former_population = yr_node_number[-1])\n",
    "        print(\"Compute average and node temperature elapsed time: {}s\".format(perf_counter() - t1))\n",
    "          \n",
    "        \n",
    "        # export node info\n",
    "        df_node_export = pd.DataFrame({'id':list(domain.G.nodes),'T': domain.node_temperature})       \n",
    "        df_node_export['tree_entropy'] = domain.node_tree_entropy\n",
    "        df_node_export.to_csv(str(lead_paper_id)+'node_'+ str(domain.evolving_until_yr)+'.csv', index = False)\n",
    "        # export edge info\n",
    "        df_edge_export = pd.DataFrame(list(domain.skeleton_tree.edges))\n",
    "        df_edge_export.columns = ['reference_id','paper_id']\n",
    "        df_edge_export.to_csv(str(lead_paper_id)+'edge_'+ str(domain.evolving_until_yr)+'.csv', index = False)\n",
    "        \n",
    "        \n",
    "        t4 = perf_counter()\n",
    "        print('total running time: {}s'.format(t4-t3))\n",
    "        print()\n",
    "        \n",
    "        yr_stamps.append(domain.evolving_until_yr)\n",
    "        yr_node_number.append(domain.num_of_nodes)\n",
    "        yr_edge_number.append(domain.num_of_edges)  \n",
    "        yr_mass.append(domain.mass)\n",
    "        yr_volume.append(domain.volume)\n",
    "        yr_avg_growth_temperatures.append(domain.average_growth_temperature)\n",
    "\n",
    "        \n",
    "    d = {'year':yr_stamps, 'node number':yr_node_number,\n",
    "         'edge number':yr_edge_number, 'mass':yr_mass, 'volume': yr_volume,\n",
    "         'T_growth_t': yr_avg_growth_temperatures,'T_struct_t': abs(np.array(yr_avg_struct_temperatures)),\n",
    "         'T_t':np.array(yr_avg_growth_temperatures)+abs(np.array(yr_avg_struct_temperatures))}    \n",
    "    df_network_evolve_info = pd.DataFrame(data=d)\n",
    "    with pd.ExcelWriter(str(lead_paper_id)+' domain stats.xlsx') as writer:\n",
    "        df_network_evolve_info.to_excel(writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0\n",
      "Evolve domain elapsed time: 0.00860419267947205s\n",
      "von neumann entropy\n",
      "2.291361239711934\n",
      "Get node reduction index elapsed time: 2.2236642273839777s\n",
      "Build skeleton tree elapsed time: 0.8759111166902862s\n",
      "Compute tree entropy elapsed time: 0.20541950243710794s\n",
      "volume:586, mass:494.41769774908636, T_growth:2.5829223433433177\n",
      "Compute average and node temperature elapsed time: 0.035238014304236565s\n",
      "total running time: 3.3738805751737604s\n",
      "\n",
      "round 1\n",
      "Evolve domain elapsed time: 0.0159661177957382s\n",
      "old E: 2.291361239711934, new_E: -4.415954206355881, struct_T: -0.008222634842834385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "von neumann entropy\n",
      "8.763838737119505\n",
      "Get node reduction index elapsed time: 51.708900355190494s\n",
      "Build skeleton tree elapsed time: 12.499493819163497s\n",
      "Compute tree entropy elapsed time: 2.77261355393955s\n",
      "volume:2235, mass:1779.6617842431435, T_growth:2.7368298243623146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute average and node temperature elapsed time: 0.3258859575104225s\n",
      "total running time: 67.48784972053387s\n",
      "\n",
      "round 2\n",
      "Evolve domain elapsed time: 0.03377007224756312s\n",
      "old E: 8.763838737119505, new_E: 7.2155948014382965, struct_T: -0.08949668063093381\n",
      "von neumann entropy\n",
      "16.418897134560595\n",
      "Get node reduction index elapsed time: 346.6668504973478s\n",
      "Build skeleton tree elapsed time: 64.14653538523163s\n",
      "Compute tree entropy elapsed time: 12.390054031410386s\n",
      "volume:4761, mass:3564.2200526686192, T_growth:2.910994690510742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute average and node temperature elapsed time: 1.5037929182639118s\n",
      "total running time: 425.29426649266225s\n",
      "\n",
      "round 3\n",
      "Evolve domain elapsed time: 0.06945449890918098s\n",
      "old E: 16.418897134560595, new_E: 15.182690365136965, struct_T: -0.13653136725976528\n",
      "von neumann entropy\n",
      "20.386706741042076\n",
      "Get node reduction index elapsed time: 1337.4071647420278s\n",
      "Build skeleton tree elapsed time: 194.6638366850109s\n",
      "Compute tree entropy elapsed time: 38.15902012134916s\n",
      "volume:8058, mass:5785.872129731568, T_growth:3.035052255184996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute average and node temperature elapsed time: 4.3217416570082605s\n",
      "total running time: 1576.0383600798748s\n",
      "\n",
      "round 4\n",
      "Evolve domain elapsed time: 0.1346931161874636s\n",
      "old E: 20.386706741042076, new_E: 33.96737163060811, struct_T: 0.011684745727391982\n",
      "von neumann entropy\n",
      "24.014021555856893\n",
      "Get node reduction index elapsed time: 4951.16711548857s\n",
      "Build skeleton tree elapsed time: 400.4496229296574s\n",
      "Compute tree entropy elapsed time: 76.38764954020553s\n",
      "volume:11202, mass:7789.448917998839, T_growth:3.1339825630751776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute average and node temperature elapsed time: 8.892258060193853s\n",
      "total running time: 5439.659167691311s\n",
      "\n",
      "round 5\n",
      "Evolve domain elapsed time: 0.22855924819305073s\n",
      "old E: 24.014021555856893, new_E: 49.578858756780186, struct_T: 0.005061165978015126\n",
      "von neumann entropy\n",
      "27.253604889190225\n",
      "Get node reduction index elapsed time: 8037.761105917854s\n",
      "Build skeleton tree elapsed time: 659.6993603185947s\n",
      "Compute tree entropy elapsed time: 119.81500333398799s\n",
      "volume:13788, mass:9374.213160838674, T_growth:3.2053406485253233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute average and node temperature elapsed time: 16.069393848887557s\n",
      "total running time: 8837.240443125971s\n",
      "\n",
      "round 6\n",
      "Evolve domain elapsed time: 0.29649467566923704s\n",
      "old E: 27.253604889190225, new_E: 6.7774620693316905, struct_T: -0.00427444415316323\n",
      "von neumann entropy\n",
      "28.26054933363467\n",
      "Get node reduction index elapsed time: 11438.462741670057s\n",
      "Build skeleton tree elapsed time: 924.6808624150763s\n",
      "Compute tree entropy elapsed time: 161.51702837468838s\n",
      "volume:15763, mass:10605.174812853717, T_growth:3.2391330318830933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute average and node temperature elapsed time: 30.13359295303235s\n",
      "total running time: 12559.760697588068s\n",
      "\n",
      "round 7\n",
      "Evolve domain elapsed time: 0.2671897848449589s\n",
      "old E: 28.26054933363467, new_E: -16.48999816017973, struct_T: -0.0010508305097180152\n",
      "von neumann entropy\n",
      "28.76054933363467\n",
      "Get node reduction index elapsed time: 14237.12583327662s\n",
      "Build skeleton tree elapsed time: 1116.6680800707181s\n",
      "Compute tree entropy elapsed time: 200.4992268885544s\n",
      "volume:16927, mass:11352.527141339822, T_growth:3.2493402213721305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute average and node temperature elapsed time: 42.23266546613013s\n",
      "total running time: 15602.421632592755s\n",
      "\n",
      "round 8\n",
      "Evolve domain elapsed time: 0.34853345077863196s\n",
      "old E: 28.76054933363467, new_E: -56.13302849005679, struct_T: -5.531978134770794e-05\n",
      "von neumann entropy\n",
      "28.76054933363467\n",
      "Get node reduction index elapsed time: 14346.428840071887s\n",
      "Build skeleton tree elapsed time: 1117.3819939258246s\n",
      "Compute tree entropy elapsed time: 219.89368509875203s\n",
      "volume:17046, mass:11431.177148790819, T_growth:3.2496700673032475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute average and node temperature elapsed time: 41.69318706335616s\n",
      "total running time: 15733.072351947834s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pioneer_id = 99188113\n",
    "getEvolvingTemperature(ref_df, paper_df, pioneer_id, evolve_step = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## domain group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DomainGroup(Domain):\n",
    "    '''\n",
    "    a group of similar domains with one pionneering paper\n",
    "    '''\n",
    "    def __init__(self, num, T):\n",
    "        self.domain_number = 0\n",
    "        self.domains = list()\n",
    "        self.domain_ages = np.zeros(num, dtype = int)\n",
    "\n",
    "        self.domain_avg_temperatures = np.zeros([T, num])\n",
    "        self.domains_helped = list() # -1: no domain to help \n",
    "        self.total_rounds = T\n",
    "        self.current_round = 0\n",
    "    \n",
    "    def initializeDomains(self, start_yrs):\n",
    "        # create domains\n",
    "        for yr in start_yrs:\n",
    "            d = Domain()\n",
    "            d.setBirthYear(yr)\n",
    "            self.domains.append(d)\n",
    "        \n",
    "    def setDomainAvgTemperatures(self, t, domain_idx, is_born = True):\n",
    "        if not is_born or self.domains[domain_idx].evolving_until_yr == self.domains[domain_idx].birth_yr:\n",
    "            self.domain_avg_temperatures[t, domain_idx] = -1\n",
    "        else:\n",
    "            self.domain_avg_temperatures[t, domain_idx] = self.domains[domain_idx].average_temperature\n",
    "        \n",
    "    def updateDomainAges(self):\n",
    "        self.domain_ages = np.array([d.evolving_until_yr - d.birth_yr for d in self.domains])\n",
    "        self.domain_ages = np.where(self.domain_ages < 0, 0, self.domain_ages)\n",
    "    \n",
    "    def decideHelpWho(self):\n",
    "        '''\n",
    "        identify the domain with the slowest growth during the last round\n",
    "        Input:\n",
    "            None\n",
    "        Output:\n",
    "            int, index of the slowest-growing domain in self.domains\n",
    "        '''\n",
    "        recent_avg_temperature_growth = np.true_divide(self.domain_avg_temperatures[self.current_round,:],\\\n",
    "                                                       self.domain_avg_temperatures[self.current_round-1,:]) \n",
    "        print(\"Decide help who\")\n",
    "        print(self.domain_avg_temperatures[self.current_round,:])\n",
    "        print(self.domain_avg_temperatures[self.current_round-1,:])\n",
    "        print(recent_avg_temperature_growth)\n",
    "        \n",
    "        if min(recent_avg_temperature_growth)>1:\n",
    "             # both/all grow, no need to help\n",
    "            return np.array([])\n",
    "        else:\n",
    "            return np.argwhere(abs(recent_avg_temperature_growth)<1).flatten()\n",
    "        \n",
    "   \n",
    "    def adjustAvgTemp(self, target_domain_idx, t):\n",
    "        '''\n",
    "        adjust the average temperature of the slowest-growing domain\n",
    "        Input: \n",
    "            target_domain_idx: index of the slowest-growing domain in self.domains\n",
    "        Output:\n",
    "            unscaled avg temperature after adjustment\n",
    "        '''\n",
    "        # get domain average temperatures before average temperature rescaling        \n",
    "        age_sum = np.sum(self.domain_ages)\n",
    "        \n",
    "        print(\"adjustAvgTemp\")\n",
    "        print(\"domain_to_help\", target_domain_idx)\n",
    "        print(\"current avg_T\")\n",
    "        print(self.domain_avg_temperatures[t])\n",
    "        \n",
    "        # all those with positive temperature increases help the rest\n",
    "        energy_to_spare = 0\n",
    "        for idx, d in enumerate(self.domains):\n",
    "            if idx not in target_domain_idx:\n",
    "                energy_to_spare += d.mass/(1+age_sum)*self.domain_avg_temperatures[t][idx]\n",
    "        return energy_to_spare        \n",
    "   \n",
    "    def updateDomainInHelp(self, target_domain_idx, t, delta_U):\n",
    "\n",
    "        delta_T = delta_U/sum([self.domains[d].mass for d in target_domain_idx])\n",
    "        \n",
    "        for i, domain in enumerate(self.domains):\n",
    "            if i in target_domain_idx:\n",
    "                new_avg_T = domain.average_temperature + delta_T\n",
    "            else:\n",
    "                new_avg_T = domain.average_temperature * sum(self.domain_ages)/(1+sum(self.domain_ages))\n",
    "            domain.node_temperature *= (new_avg_T/domain.average_temperature) \n",
    "            domain.average_struct_temperature *= (new_avg_T/domain.average_temperature)\n",
    "            domain.average_growth_temperature *= (new_avg_T/domain.average_temperature)\n",
    "            domain.average_temperature = new_avg_T\n",
    "       \n",
    "        \n",
    "    \n",
    "    def updateDomainGroupRecord(self, target_domain_idx = None, t = None):\n",
    "        self.current_round += 1\n",
    "        self.domain_number = len(np.nonzero(self.domain_ages)[0])\n",
    "        if target_domain_idx:\n",
    "            for i, domain in enumerate(self.domains):\n",
    "                self.domain_avg_temperatures[t, i] = domain.average_temperature if domain.average_temperature>0 else -1\n",
    "            self.domains_helped.append(target_domain_idx)\n",
    "            print(\"updateDomainGroupRecord\")\n",
    "            print(self.domain_avg_temperatures)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run multiple domains T evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEvolvingTemperatureForest(df_ref_list, df_paper_list, lead_paper_ids, evolve_step=1):\n",
    "    '''\n",
    "    Compute evolving node temperature based on domain skeleton tree, node tree entropy and forest helping mechanism\n",
    "    Visualise every evolve_step-year\n",
    "    Input: \n",
    "        df_ref_list: pandas Dataframe, columns = ['paper_id','reference_id','year'], each df is a domain\n",
    "        df_paper_list: pandas Dataframe, columns = ['paper_id','year'], each df is a domain\n",
    "        lead_paper_ids: list of int, original ids of the pionneering work\n",
    "        evolve_step: interval between 2 visualization, unit: year \n",
    "    Output:\n",
    "        None\n",
    "    '''\n",
    "    # initialize domain group\n",
    "    N = len(df_ref_list)\n",
    "    start_years = [df['year'].min() for df in df_ref_list]\n",
    "    end_years = [df['year'].max() for df in df_ref_list]\n",
    "    domain_rank = np.argsort(start_years)\n",
    "    ordered_df_ref_list = list()\n",
    "    ordered_df_paper_list = list()\n",
    "    ordered_lead_paper_ids = list()\n",
    "    for i in range(N):\n",
    "        old_idx = np.argwhere(domain_rank == i).flatten()[0]\n",
    "        ordered_df_ref_list.append(df_ref_list[old_idx])\n",
    "        ordered_df_paper_list.append(df_paper_list[old_idx])\n",
    "        ordered_lead_paper_ids.append(lead_paper_ids[old_idx])\n",
    "    T = int((max(end_years) - min(start_years))/evolve_step)\n",
    "    delta = (max(end_years) - min(start_years))%evolve_step  # the beginning period where there's only one domain \n",
    "    \n",
    "    # initialize domains\n",
    "    domain_group = DomainGroup(N, T+1)\n",
    "    domain_group.initializeDomains(sorted(start_years))\n",
    "    \n",
    "    # judge if big graph, for T_growth_t\n",
    "    are_big_graphs = list([True if df.shape[0]>5000 else False for df in ordered_df_paper_list])\n",
    "    \n",
    "    # record network size and average temperature for visualization\n",
    "    yr_stamps = list()\n",
    "    yr_node_number = np.zeros([T+1,N], dtype = int)\n",
    "    yr_edge_number = np.zeros([T+1,N], dtype = int)\n",
    "    yr_mass =  np.zeros([T+1,N])\n",
    "    yr_volume = np.zeros([T+1,N])\n",
    "    von_neumann_entropies = np.zeros([T+1,N])\n",
    "    von_neumann_entropies_shrink = np.zeros([T,N])\n",
    "    yr_avg_temperature = np.zeros([T+1,N])\n",
    "    \n",
    "    current_yr = min(start_years)+delta\n",
    "    \n",
    "    prev_avg_growth_temperature = np.zeros(N)\n",
    "    \n",
    "    for t in range(T+1):\n",
    "        \n",
    "        print('round',t)\n",
    "        t3 = perf_counter()\n",
    "        \n",
    "        print('Current year', current_yr)\n",
    "        \n",
    "        t1 = perf_counter()\n",
    "        for domain_idx, (domain, lead_paper_id, df, paper_df,is_big_graph) in enumerate(zip(domain_group.domains,\n",
    "                                                                                   ordered_lead_paper_ids, \n",
    "                                                                                   ordered_df_ref_list,\n",
    "                                                                                   ordered_df_paper_list,\n",
    "                                                                                   are_big_graphs)):\n",
    "            \n",
    "            if domain.birth_yr >= current_yr+evolve_step:\n",
    "                # not born by the end of this round\n",
    "                domain_group.setDomainAvgTemperatures(t, domain_idx, is_born = False)\n",
    "                continue    \n",
    "            \n",
    "            prev_G = deepcopy(domain.G)\n",
    "                \n",
    "            domain.evolve(df, lead_paper_id, current_yr, evolve_step)\n",
    "            \n",
    "            if prev_G.number_of_nodes():\n",
    "                # get equivalent shrinked network, remove all new nodes, add edges between old nodes\n",
    "                curr_G = deepcopy(domain.G)\n",
    "                H, delta_edge_sum = get_von_neumann_E_shrinked(prev_G, curr_G, paper_df)\n",
    "                H_prev = von_neumann_entropies[t-1, domain_idx]\n",
    "                try:\n",
    "                    struct_Temperature = delta_edge_sum/(H - H_prev) if delta_edge_sum else 0\n",
    "                except: # float division by 0 error\n",
    "                    struct_Temperature = 10*delta_edge_sum  \n",
    "                avg_struct_T = struct_Temperature/domain.num_of_nodes \n",
    "                domain.setStructTemperature(avg_struct_T)\n",
    "                von_neumann_entropies_shrink[t-1, domain_idx] = H\n",
    "            else:\n",
    "                # first round, no struct change\n",
    "                domain.setStructTemperature(0)\n",
    "            \n",
    "            domain.getVonNeumannEntropy()\n",
    "            von_neumann_entropies[t, domain_idx] = domain.von_neumann_entropy\n",
    "       \n",
    "            domain.setNodeReductionIdx()\n",
    "          \n",
    "            domain.buildSkeletonTree()\n",
    "        \n",
    "            domain.setNodeTreeEntropy()\n",
    "\n",
    "            ## compute domain average temperature and node temperature\n",
    "            if prev_G.number_of_nodes() == 0:    \n",
    "                domain.getAvgTemperature(is_initial = True, is_big_graph = is_big_graph)\n",
    "                domain.spreadTemperature(former_population = 0)\n",
    "            else:    \n",
    "                domain.getAvgTemperature(is_initial = False, is_big_graph = is_big_graph,\n",
    "                                         old_avg_temperature = prev_avg_growth_temperature[domain_idx],\n",
    "                                         old_V = yr_volume[t-1, domain_idx],\n",
    "                                         old_N = yr_mass[t-1, domain_idx])\n",
    "                domain.spreadTemperature(former_population = yr_node_number[t-1, domain_idx])\n",
    "            \n",
    "            # update group avg temperature\n",
    "            domain_group.setDomainAvgTemperatures(t, domain_idx)\n",
    "                \n",
    "        print(\"Evolve domain group: {}s\".format(perf_counter() - t1))\n",
    "        \n",
    "        \n",
    "        print(\"avg_T before adjustment: \")    \n",
    "        print([d.average_temperature for d in domain_group.domains])\n",
    "        \n",
    "        print(\"avg_struct_T:\")\n",
    "        print([d.average_struct_temperature for d in domain_group.domains])\n",
    "        \n",
    "        domain_group.updateDomainAges()\n",
    "        print(\"domain ages:\", domain_group.domain_ages)\n",
    "        \n",
    "        if domain_group.domain_number >= 2:\n",
    "            # forest helping mechanism\n",
    "            t1 = perf_counter()\n",
    "            domain_to_help = domain_group.decideHelpWho()\n",
    "            print(\"domain_to_help\", domain_to_help)\n",
    "            if len(list(domain_to_help)):\n",
    "                energy_to_share = domain_group.adjustAvgTemp(domain_to_help, t) \n",
    "                domain_group.updateDomainInHelp(domain_to_help, t, energy_to_share)\n",
    "            domain_group.updateDomainGroupRecord(list(domain_to_help), t)\n",
    "            print(\"Forest helping: {}s\".format(perf_counter() - t1))\n",
    "        else:\n",
    "            domain_group.updateDomainGroupRecord()\n",
    "            \n",
    "        # output domain group evolution after forest helping  \n",
    "        for i, (domain, lead_paper_id) in enumerate(zip(domain_group.domains, ordered_lead_paper_ids)):\n",
    "#             # export node info\n",
    "#             df_node_export = pd.DataFrame({'id':list(domain.G.nodes),'T': domain.node_temperature})       \n",
    "#             df_node_export['tree_entropy'] = domain.node_tree_entropy\n",
    "#             df_node_export.to_csv(str(lead_paper_id)+'node_'+str(t)+'_'+ str(domain.evolving_until_yr)+'.csv', index = False)\n",
    "#             # export edge info\n",
    "#             df_edge_export = pd.DataFrame(list(domain.skeleton_tree.edges))\n",
    "#             df_edge_export.columns = ['reference_id','paper_id']\n",
    "#             df_edge_export.to_csv(str(lead_paper_id)+'edge_'+str(t)+'_'+ str(domain.evolving_until_yr)+'.csv', index = False)\n",
    "            \n",
    "            yr_node_number[t, i] = domain.num_of_nodes\n",
    "            yr_edge_number[t, i] = domain.num_of_edges\n",
    "            yr_mass[t, i] = domain.mass\n",
    "            yr_volume[t, i] = domain.volume\n",
    "            yr_avg_temperature[t, i] = domain.average_temperature\n",
    "            prev_avg_growth_temperature[i] = domain.average_growth_temperature \n",
    "        \n",
    "        yr_stamps.append(current_yr+evolve_step-1)\n",
    "        current_yr += evolve_step\n",
    "        \n",
    "        t4 = perf_counter()\n",
    "        print('total running time: {}s'.format(t4-t3))\n",
    "        print()\n",
    "        \n",
    "    \n",
    "    # output stats for each domain\n",
    "    for i, (domain, pioneer_id) in enumerate(zip(domain_group.domains, ordered_lead_paper_ids)):\n",
    "        d = {'year':yr_stamps, 'node number':yr_node_number[:,i],\n",
    "             'edge number':yr_edge_number[:,i], 'mass':yr_mass[:,i], 'volume': yr_volume[:,i],\n",
    "             'T_t forest':yr_avg_temperature[:,i]}    \n",
    "        df_network_evolve_info = pd.DataFrame(data=d)\n",
    "        with pd.ExcelWriter(str(pioneer_id)+' domain stats.xlsx') as writer:\n",
    "            df_network_evolve_info.to_excel(writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0\n",
      "Current year 1998\n",
      "von neumann entropy\n",
      "0\n",
      "volume:17, mass:14.333333333333332, T_growth:2.7473041750434675\n",
      "Evolve domain group: 0.020964462601114064s\n",
      "avg_T before adjustment: \n",
      "[2.7473041750434675, 0]\n",
      "avg_struct_T:\n",
      "[0, 0]\n",
      "domain ages: [2 0]\n",
      "total running time: 0.022342840580677148s\n",
      "\n",
      "round 1\n",
      "Current year 2000\n",
      "von neumann entropy\n",
      "0.25\n",
      "volume:56, mass:37.4404703686275, T_growth:3.464589273381462\n",
      "Evolve domain group: 0.054918259964324534s\n",
      "avg_T before adjustment: \n",
      "[inf, 0]\n",
      "avg_struct_T:\n",
      "[inf, 0]\n",
      "domain ages: [4 0]\n",
      "total running time: 0.05551418188406387s\n",
      "\n",
      "round 2\n",
      "Current year 2002\n",
      "von neumann entropy\n",
      "0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n",
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:79: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n",
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:388: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume:102, mass:62.77337411892641, T_growth:3.763827615927091\n",
      "Evolve domain group: 0.13890023138810648s\n",
      "avg_T before adjustment: \n",
      "[3.86393870877533, 0]\n",
      "avg_struct_T:\n",
      "[0.10011109284823903, 0]\n",
      "domain ages: [6 0]\n",
      "total running time: 0.14021831194258993s\n",
      "\n",
      "round 3\n",
      "Current year 2004\n",
      "von neumann entropy\n",
      "1.5455555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume:156, mass:95.06520149887511, T_growth:3.8010891092095727\n",
      "Evolve domain group: 0.37413988015032373s\n",
      "avg_T before adjustment: \n",
      "[3.944057878986084, 0]\n",
      "avg_struct_T:\n",
      "[0.142968769776511, 0]\n",
      "domain ages: [8 0]\n",
      "total running time: 0.37523122828133637s\n",
      "\n",
      "round 4\n",
      "Current year 2006\n",
      "von neumann entropy\n",
      "2.0455555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume:230, mass:140.19174045350655, T_growth:3.8002348312228866\n",
      "Evolve domain group: 0.9286046752749826s\n",
      "avg_T before adjustment: \n",
      "[3.9392476671263257, 0]\n",
      "avg_struct_T:\n",
      "[0.13901283590343919, 0]\n",
      "domain ages: [10  0]\n",
      "total running time: 0.9296480675548082s\n",
      "\n",
      "round 5\n",
      "Current year 2008\n",
      "von neumann entropy\n",
      "2.8580555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume:331, mass:198.97754361246294, T_growth:3.853265678903287\n",
      "Evolve domain group: 1.7859007694787579s\n",
      "avg_T before adjustment: \n",
      "[3.9741139170073496, 0]\n",
      "avg_struct_T:\n",
      "[0.12084823810406276, 0]\n",
      "domain ages: [12  0]\n",
      "total running time: 1.787169131101109s\n",
      "\n",
      "round 6\n",
      "Current year 2010\n",
      "von neumann entropy\n",
      "3.1080555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume:422, mass:253.3020974263493, T_growth:3.8590347618678877\n",
      "Evolve domain group: 3.2167089453869266s\n",
      "avg_T before adjustment: \n",
      "[4.12037991196777, 0]\n",
      "avg_struct_T:\n",
      "[0.2613451500998826, 0]\n",
      "domain ages: [14  0]\n",
      "total running time: 3.2173270821440383s\n",
      "\n",
      "round 7\n",
      "Current year 2012\n",
      "von neumann entropy\n",
      "3.6080555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume:568, mass:326.99643035287977, T_growth:4.023558773652101\n",
      "Evolve domain group: 5.965424892325245s\n",
      "avg_T before adjustment: \n",
      "[4.156211905140087, 0]\n",
      "avg_struct_T:\n",
      "[0.1326531314879866, 0]\n",
      "domain ages: [16  0]\n",
      "total running time: 5.9662246265943395s\n",
      "\n",
      "round 8\n",
      "Current year 2014\n",
      "von neumann entropy\n",
      "9.738741649374905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume:1323, mass:722.6002983485112, T_growth:4.240984969423558\n",
      "von neumann entropy\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n",
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume:53, mass:43.82295293582148, T_growth:22.686486647111415\n",
      "Evolve domain group: 50.43435197194049s\n",
      "avg_T before adjustment: \n",
      "[4.58854574023221, 22.686486647111415]\n",
      "avg_struct_T:\n",
      "[0.34756077080865144, 0]\n",
      "domain ages: [18  0]\n",
      "total running time: 50.43464076486998s\n",
      "\n",
      "round 9\n",
      "Current year 2016\n",
      "von neumann entropy\n",
      "22.943800206311778\n",
      "volume:5912, mass:3239.8794781605966, T_growth:4.226789267756797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "von neumann entropy\n",
      "1.0\n",
      "volume:749, mass:543.2299835516064, T_growth:25.86372640978375\n",
      "Evolve domain group: 1335.942916321983s\n",
      "avg_T before adjustment: \n",
      "[4.316336523799092, 25.879889605998056]\n",
      "avg_struct_T:\n",
      "[-0.08954725604229453, -0.016163196214303642]\n",
      "domain ages: [20  2]\n",
      "total running time: 1335.9446293330402s\n",
      "\n",
      "round 10\n",
      "Current year 2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "von neumann entropy\n",
      "32.46070203391161\n",
      "volume:15279, mass:6023.455195913657, T_growth:5.875627735649048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "von neumann entropy\n",
      "2.0555555555555554\n",
      "volume:2109, mass:1459.0347270719608, T_growth:27.114647548324935\n",
      "Evolve domain group: 16589.183018199947s\n",
      "avg_T before adjustment: \n",
      "[5.9217890486892335, 27.379627596749337]\n",
      "avg_struct_T:\n",
      "[-0.046161313040185836, 0.2649800484244014]\n",
      "domain ages: [22  4]\n",
      "Decide help who\n",
      "[ 5.92178905 27.3796276 ]\n",
      "[ 4.31633652 25.87988961]\n",
      "[1.37194795 1.05794994]\n",
      "domain_to_help []\n",
      "Forest helping: 0.002092779046506621s\n",
      "total running time: 16589.195484957025s\n",
      "\n",
      "round 11\n",
      "Current year 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "von neumann entropy\n",
      "32.766257589467166\n",
      "volume:16777, mass:6610.636385225673, T_growth:5.878629104785079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "von neumann entropy\n",
      "2.3055555555555554\n",
      "volume:2282, mass:1576.6176732051877, T_growth:27.15077697134515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evolve domain group: 19879.774643839686s\n",
      "avg_T before adjustment: \n",
      "[5.953613119969601, 27.16182623303536]\n",
      "avg_struct_T:\n",
      "[0.0749840151845222, 0.011049261690210359]\n",
      "domain ages: [23  5]\n",
      "Decide help who\n",
      "[ 5.95361312 27.16182623]\n",
      "[ 5.92178905 27.3796276 ]\n",
      "[1.00537406 0.99204513]\n",
      "domain_to_help [1]\n",
      "adjustAvgTemp\n",
      "domain_to_help [1]\n",
      "current avg_T\n",
      "[ 5.95361312 27.16182623]\n",
      "updateDomainGroupRecord\n",
      "[[ 2.74730418 -1.        ]\n",
      " [        inf -1.        ]\n",
      " [ 3.86393871 -1.        ]\n",
      " [ 3.94405788 -1.        ]\n",
      " [ 3.93924767 -1.        ]\n",
      " [ 3.97411392 -1.        ]\n",
      " [ 4.12037991 -1.        ]\n",
      " [ 4.15621191 -1.        ]\n",
      " [ 4.58854574 -1.        ]\n",
      " [ 4.31633652 25.87988961]\n",
      " [ 5.92178905 27.3796276 ]\n",
      " [ 5.74831612 28.02262075]]\n",
      "Forest helping: 0.005970502912532538s\n",
      "total running time: 19879.783884155593s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# wireless networks\n",
    "# ref_df1 = pd.read_csv(r'wireless networks forest/62270017domain_reference.csv')\n",
    "# ref_df2 = pd.read_csv(r'wireless networks forest/438420345domain_reference.csv')\n",
    "# paper_df1 = pd.read_csv(r'wireless networks forest/62270017domain_paper.csv')\n",
    "# paper_df2 = pd.read_csv(r'wireless networks forest/438420345domain_paper.csv')\n",
    "\n",
    "# GRU LSTM\n",
    "ref_df1 = pd.read_csv(r'RNN memory layer forest/168338164domain_reference.csv')\n",
    "ref_df2 = pd.read_csv(r'RNN memory layer forest/56158074domain_reference.csv')\n",
    "paper_df1 = pd.read_csv(r'RNN memory layer forest/168338164domain_paper.csv')\n",
    "paper_df2 = pd.read_csv(r'RNN memory layer forest/56158074domain_paper.csv')\n",
    "\n",
    "# RNN word embeddings\n",
    "# ref_df1 = pd.read_csv(r'word embedding forest/223688399domain_reference.csv')\n",
    "# ref_df2 = pd.read_csv(r'word embedding forest/256500874domain_reference.csv')\n",
    "# ref_df3 = pd.read_csv(r'word embedding forest/372720438domain_reference.csv')\n",
    "# paper_df1 = pd.read_csv(r'word embedding forest/223688399domain_paper.csv')\n",
    "# paper_df2 = pd.read_csv(r'word embedding forest/256500874domain_paper.csv')\n",
    "# paper_df3 = pd.read_csv(r'word embedding forest/372720438domain_paper.csv')\n",
    "\n",
    "# df_ref_list = [ref_df1, ref_df2, ref_df3]\n",
    "# df_paper_list = [paper_df1, paper_df2, paper_df3]\n",
    "# lead_paper_ids = [223688399, 256500874, 372720438]\n",
    "df_ref_list = [ref_df1, ref_df2]\n",
    "df_paper_list = [paper_df1, paper_df2]\n",
    "lead_paper_ids = [168338164, 56158074]\n",
    "getEvolvingTemperatureForest(df_ref_list, df_paper_list, lead_paper_ids, evolve_step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
