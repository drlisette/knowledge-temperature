{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> get evolving temperature for academic paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from time import perf_counter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from itertools import product, combinations, chain\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Domain:\n",
    "    '''\n",
    "    Domain with one pionneering paper\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.G = nx.DiGraph()  # citation graph\n",
    "        self.pioneer_node = 0  # pionneering node id in G, not the original one\n",
    "        self.num_of_nodes = 0 \n",
    "        self.num_of_edges = 0\n",
    "        \n",
    "        self.skeleton_tree = nx.DiGraph()\n",
    "        self.node_node_reduction_index = None\n",
    "        self.node_network_reduction_index = None\n",
    "        self.node_node_average_step = 0\n",
    "        \n",
    "        self.average_temperature = 0\n",
    "        self.average_growth_temperature = 0\n",
    "        self.average_struct_temperature = 0\n",
    "        self.volume = 0  # int\n",
    "        self.mass = 0  # float\n",
    "        self.node_tree_entropy = None # structure entropy based on skeleton tree\n",
    "        self.node_temperature = None\n",
    "        self.evolving_until_yr = 0\n",
    "        self.birth_yr = 0\n",
    "        \n",
    "        self.von_neumann_entropy = 0 # G's von-Neumann entropy\n",
    "        \n",
    "    def setBirthYear(self, yr):\n",
    "        self.birth_yr = yr\n",
    "        \n",
    "    def evolve(self, df, lead_paper_id, start_yr, step=1):\n",
    "        '''\n",
    "        Evolve ahead and reinitialize parameters\n",
    "        Input: \n",
    "            df: pd.DataFrame, reference information\n",
    "            lead_paper_id: int, ID of the pioneering work\n",
    "            start_yr: int, current timestamp\n",
    "            step: int, evolution window (in year)\n",
    "        '''\n",
    "        # extract reference for a year\n",
    "        df_t = df[(df['year']>= start_yr) & (df['year']< start_yr+step)][['paper_id','reference_id']]\n",
    "        G_t = nx.from_pandas_edgelist(df_t, source = 'reference_id', target = 'paper_id', create_using = nx.DiGraph)\n",
    "        self.G.add_nodes_from(G_t.nodes)\n",
    "        self.G.add_edges_from(G_t.edges)\n",
    "        \n",
    "        # add self-loop for pioneer paper (if no self-loop yet in G)\n",
    "        self.G.add_edge(lead_paper_id, lead_paper_id)\n",
    "\n",
    "        # initialize class attributes\n",
    "        self.pioneer_node = np.argwhere(np.array(self.G.nodes)==lead_paper_id).flatten()[0]\n",
    "        self.num_of_nodes = self.G.number_of_nodes()\n",
    "        self.num_of_edges = self.G.number_of_edges()\n",
    "        self.node_node_reduction_index = np.zeros((self.num_of_nodes, self.num_of_nodes))\n",
    "        self.node_network_reduction_index = np.empty(self.num_of_nodes)\n",
    "        self.node_tree_entropy = np.empty(self.num_of_nodes)\n",
    "        self.node_temperature = np.empty(self.num_of_nodes)\n",
    "        self.evolving_until_yr = min(start_yr+step-1, 2020)\n",
    "        \n",
    "        # clear last round's weight attribute\n",
    "        for (n1, n2, d) in self.G.edges(data=True):\n",
    "            d.clear()\n",
    "        \n",
    "        self.von_neumann_entropy = 0\n",
    "        self.average_temperature = 0\n",
    "        self.average_growth_temperature = 0\n",
    "        self.average_struct_temperature = 0\n",
    "        \n",
    "    def getVonNeumannEntropy(self):\n",
    "        '''\n",
    "        Compute G's von neumann entropy \n",
    "        '''\n",
    "        for c in sorted(nx.strongly_connected_components(self.G), key=len, reverse=True):\n",
    "            sc_node_num = len(c)\n",
    "            if sc_node_num>1:\n",
    "                sub_G = self.G.subgraph(c).copy()\n",
    "                # add weight attr \n",
    "                nx.set_edge_attributes(sub_G, 1,'weight')\n",
    "                # get res\n",
    "                res = sum([wgt**2 * sub_G.in_degree(u)/sub_G.in_degree(v)/sub_G.out_degree(u)**2 \\\n",
    "                           for (u,v,wgt) in sub_G.edges.data('weight')])  #combinations(c, 2):   \n",
    "                self.von_neumann_entropy += 1-1/sc_node_num - res/2/sc_node_num**2\n",
    "            else:\n",
    "                # strongly connected component containing 1 node\n",
    "                # von neumann entropy = 0\n",
    "                break   \n",
    "    \n",
    "    def setNodeReductionIdx(self):\n",
    "        '''\n",
    "        Compute node-node and node-network reduction index\n",
    "        Output:\n",
    "            Reduction_idx: a 2-D array of size (# node number * # node number)\n",
    "        '''\n",
    "        node_embeddings = self.getNodeEmbedding()\n",
    "        # node distance in embedding space\n",
    "        sparse_distance_mtrx = sparse.csr_matrix(self.getNodeDistance(node_embeddings.A))  # matrix.A  convert from matrix to ndarray\n",
    "        # weighted sparse adj matrix \n",
    "        sparse_adjacency_mtrx  = nx.to_scipy_sparse_matrix(self.G)\n",
    "        sparse_weighted_adj_mtrx = sparse_adjacency_mtrx.multiply(sparse_distance_mtrx) # element wise multiplication\n",
    "        # maximal node-pair distance in embedding space\n",
    "        max_distance = sparse_weighted_adj_mtrx.max()\n",
    "        # build weighted graph from sparse adj matrix\n",
    "        weighted_G = nx.from_scipy_sparse_matrix(sparse_weighted_adj_mtrx, create_using = nx.DiGraph, edge_attribute='weight')\n",
    "        # average node pair shortest distance \n",
    "        shortest_paths = dict(nx.all_pairs_dijkstra_path(weighted_G, weight='weight'))\n",
    "        self.node_node_average_step = self.getAvgStep(shortest_paths)\n",
    "        \n",
    "        # node-node reduction index\n",
    "        wgts = nx.get_edge_attributes(weighted_G, 'weight')\n",
    "        for i,j in product(range(self.num_of_nodes),range(self.num_of_nodes)):  # i --> j, find j's predecessors\n",
    "            if i==j:\n",
    "                continue \n",
    "            # get all shortest paths from i to j's references     \n",
    "            paths = list([shortest_paths[i].get(pre_j, []) for pre_j in weighted_G.predecessors(j)])\n",
    "            for p in paths:\n",
    "                if not p:  # if p is an empty list\n",
    "                    self.node_node_reduction_index[i,j] += max_distance * self.node_node_average_step\n",
    "                if len(p)>1:  # len(p)==1, path to itself, self-loop, no reduction     \n",
    "                    self.node_node_reduction_index[i,j] += np.sum([wgts[(p[i],p[i+1])] for i in range(len(p)-1)]) \n",
    "        \n",
    "        # add edge weight\n",
    "        mapping = {i:u for i,u in enumerate(self.G.nodes)}\n",
    "        nx.relabel_nodes(weighted_G, mapping, copy = False)\n",
    "        self.G = weighted_G\n",
    "        \n",
    "        # node-network reduction index\n",
    "        self.node_network_reduction_index = self.node_node_reduction_index.T @ np.ones((self.num_of_nodes,1))\n",
    "    \n",
    "    def buildSkeletonTree(self):\n",
    "        '''\n",
    "        Build skeleton tree by trimming citation graph\n",
    "       \n",
    "        '''\n",
    "        # skeleton tree\n",
    "        T = deepcopy(self.G)\n",
    "        \n",
    "        ### Step 1\n",
    "        # detect loops in T\n",
    "        # cut an edge whose extremities have the biggest difference in reduction index \n",
    "        # keep graph connectivity \n",
    "        for i, src in enumerate(list(T.nodes)):\n",
    "            for target in list(T.nodes)[i+1:]: # src != target\n",
    "                if nx.has_path(T, src, target) and nx.has_path(T, target, src):\n",
    "                    has_loop = True\n",
    "                    while has_loop:\n",
    "                        try:\n",
    "                            loop = nx.shortest_path(T, source=src, target=target)[:-1] + \\\n",
    "                                   nx.shortest_path(T, source=target, target=src)\n",
    "                            self.cutEdgeInLoop(T, loop)\n",
    "                        except:\n",
    "                            has_loop = False\n",
    "\n",
    "        ### Step 2\n",
    "        # leave only one predecessor/reference for each paper\n",
    "        # remove directed edges\n",
    "        domain_nodes = T.nodes\n",
    "        for i,n in enumerate(domain_nodes):\n",
    "            pre_n = list(T.predecessors(n))\n",
    "            pre_n_idx = [np.argwhere(np.array(domain_nodes)==j).flatten()[0] for j in pre_n]\n",
    "            self_network_reduction_idx = self.node_network_reduction_index[i]\n",
    "            if len(pre_n)>1:\n",
    "                delta_reduction_idx = np.array([abs(self.node_network_reduction_index[j] -\n",
    "                                                    self_network_reduction_idx) for j in pre_n_idx])\n",
    "                reference_to_keep = pre_n.pop(np.argmin(delta_reduction_idx))      \n",
    "                for src in pre_n:\n",
    "                    T.remove_edge(src, n)          \n",
    "                    \n",
    "        self.skeleton_tree = T   \n",
    "        \n",
    "    def setNodeTreeEntropy(self):\n",
    "        '''\n",
    "        Compute tree entropy based on skeleton tree\n",
    "        Output:\n",
    "            T: nx.graph.DiGraph, same skeleton tree with tree entropy added as a node attribute\n",
    "        '''\n",
    "        T = self.skeleton_tree\n",
    "        m = T.number_of_edges()\n",
    "        node_set = set(T.nodes)\n",
    "    \n",
    "        for i,n in enumerate(T.nodes):\n",
    "            if i==self.pioneer_node:\n",
    "                self.node_tree_entropy[i] = 0\n",
    "            else:    \n",
    "                A_set = self.getSubTreeNodes([n])\n",
    "                n_parents = list(T.predecessors(n))\n",
    "                sub_parent_T_nodes  = self.getSubTreeNodes(n_parents)\n",
    "                sub_T_volume = max(nx.volume(T, list(A_set), weight = None),1)  # sub_T_nodes\n",
    "                if sub_parent_T_nodes:\n",
    "                    self.node_tree_entropy[i] = -sub_T_volume/(2*m)*np.log(len(A_set)/len(sub_parent_T_nodes))\n",
    "                else:\n",
    "                    self.node_tree_entropy[i] = 0  # isolated node\n",
    "                \n",
    "    def setStructTemperature(self, T):\n",
    "        self.average_struct_temperature = T\n",
    "    \n",
    "    def getAvgTemperature(self, is_initial = True, is_big_graph = True, old_avg_temperature = 0, old_V = 0, old_N = 0):\n",
    "        '''\n",
    "        Compute volume, mass and average temperature based on skeleton tree\n",
    "        Input: \n",
    "            is_initial: boolean, whether time stamp = 0\n",
    "            old_avg_temperature: float, average growth temperature for the last time stamp\n",
    "            old_V: int, volume of the last time stamp\n",
    "            old_N: float, mass of the last time stamp       \n",
    "        '''\n",
    "        ###### get average growth temperature \n",
    "        Tree = self.skeleton_tree\n",
    "        # volume\n",
    "        self.volume = self.num_of_nodes\n",
    "        # rescale node-node reduction index\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_node_reduction_index = scaler.fit_transform(self.node_node_reduction_index)\n",
    "        # mass\n",
    "        tree_adj = nx.to_scipy_sparse_matrix(Tree).todense()\n",
    "        tree_adj = np.where(tree_adj == 0,tree_adj, 1)\n",
    "        self.mass = self.num_of_nodes - np.sum(np.multiply(scaled_node_reduction_index, tree_adj))\n",
    "        # scaling coef\n",
    "        coef = 10 if is_big_graph else 100\n",
    "        if is_initial:\n",
    "            # entropy \n",
    "            S = np.sum(self.node_tree_entropy)\n",
    "            # set default constant\n",
    "            R = 8\n",
    "            c = 1 \n",
    "            self.average_growth_temperature =  coef * np.exp(S/(c*self.mass)) * np.float_power(self.mass/self.volume,R/c)\n",
    "        else:\n",
    "            self.average_growth_temperature = old_avg_temperature * (self.volume/old_V) * (old_N/self.mass)\n",
    "        print(\"volume:{}, mass:{}, T_growth:{}\".format(self.volume, self.mass, self.average_growth_temperature))  \n",
    "        \n",
    "        ###### get average temperature\n",
    "        self.average_temperature = self.average_growth_temperature + abs(self.average_struct_temperature)\n",
    "            \n",
    "    \n",
    "    def spreadTemperature(self, former_population = 0):\n",
    "        '''\n",
    "        Compute node knowledge temperature\n",
    "        Input: \n",
    "            former_population: int, node number by the end of last timestamp\n",
    "        '''\n",
    "        # get inactive nodes \n",
    "        coldest_nodes = self.getInactiveNodes(former_population)\n",
    "            \n",
    "        # add distance attribute to domain reference graph\n",
    "        scaler = MinMaxScaler(feature_range = (0.5,1.5))\n",
    "        scaled_node_node_reduction_idx = scaler.fit_transform(self.node_node_reduction_index)\n",
    "        node_list = list(self.G.nodes)\n",
    "        for u,v in self.G.edges:\n",
    "            self.G.edges[u,v]['distance'] = scaled_node_node_reduction_idx[node_list.index(u)][node_list.index(v)] \n",
    "\n",
    "        # get node temperature     \n",
    "        self.node_temperature = self.diffuseHeat(self.pioneer_node, coldest_nodes, int(self.node_node_average_step))   \n",
    "        \n",
    "                        \n",
    "    ########## auxiliary functions ##########\n",
    "    def getNodeEmbedding(self):\n",
    "        '''\n",
    "        Get spectral embedding\n",
    "        '''\n",
    "        sparse_adjacency_mtrx  = nx.to_scipy_sparse_matrix(self.G)\n",
    "        sparse_degree_mtrx = np.diagflat(sparse_adjacency_mtrx.T @ np.ones((sparse_adjacency_mtrx.shape[0],1), dtype=int))\n",
    "        # Laplacian matrix \n",
    "        L = sparse_degree_mtrx - sparse_adjacency_mtrx.T\n",
    "        # regular Laplacian matrix\n",
    "        L_regular = np.sqrt(sparse_degree_mtrx) @ L @ np.sqrt(sparse_degree_mtrx)       \n",
    "        # node embedding (projected dimension = # node number)\n",
    "        _, eigvecs = np.linalg.eig(L_regular)\n",
    "        return eigvecs\n",
    "    \n",
    "    def getNodeDistance(self, M):\n",
    "        '''\n",
    "        Create distance matrix in embedding space \n",
    "        Extract node-pair distance for the graph\n",
    "        Input: \n",
    "            M: 2-D ndarray, eigenvectors of the regular Laplacian matrix, each row is a vector\n",
    "        Output:\n",
    "            D: 2-D ndarray, distance matrix of the graph\n",
    "        '''\n",
    "        N = M.shape[0]\n",
    "        D = np.empty(M.shape)\n",
    "        for i in range(N):\n",
    "            for j in range(i, N):\n",
    "                d = np.linalg.norm(M[i] - M[j]) # 2-norm\n",
    "                D[i,j], D[j,i] = d, d\n",
    "        return D \n",
    "                        \n",
    "    def getAvgStep(self, paths):\n",
    "        '''\n",
    "        Get the average shortest path in citation graph\n",
    "        Input: \n",
    "            paths: dict of lists, shortest paths dictionary\n",
    "        Output: \n",
    "            float, average shortest path length\n",
    "        '''\n",
    "        total_step = 0\n",
    "        path_counter = 0                        \n",
    "        for path_dict in paths.values():\n",
    "            steps = [len(p)-1 for p in path_dict.values()]\n",
    "            total_step += np.sum(steps)\n",
    "            path_counter += len(path_dict)-1\n",
    "        return total_step/path_counter               \n",
    "    \n",
    "    def cutEdgeInLoop(self, T, loop):\n",
    "        '''\n",
    "        Cut an edge in a loop in skeleton tree\n",
    "        Input:\n",
    "            T: networkx.graph.DiGraph, skeleton tree\n",
    "            loop: list of int, represents a loop\n",
    "        Output:\n",
    "            None. T is already modified (dict object is changeable) \n",
    "        '''\n",
    "        nodes = np.array(T.nodes)\n",
    "        is_cut = False\n",
    "        edges_to_cut = dict([((loop[i], loop[i+1]), \n",
    "                              abs(self.node_network_reduction_index[i+1] - self.node_network_reduction_index[i])) \n",
    "                             for i in range(len(loop)-1)])\n",
    "        edges_to_cut = sorted(edges_to_cut.items(), key = lambda x: x[1], reverse=True) # sort by network reduction index \n",
    "        for edge,val in edges_to_cut:\n",
    "            if len(list(T.predecessors(edge[1]))) > 1:\n",
    "                T.remove_edge(edge[0], edge[1])\n",
    "                is_cut = True\n",
    "        if not is_cut:\n",
    "            T.remove_edge(edges_to_cut[0][0][0], edges_to_cut[0][0][1])\n",
    "                    \n",
    "    def getSubTreeNodes(self, parents):\n",
    "        '''\n",
    "        Find all the children of node n in domain skeleton tree, BFS search\n",
    "        Input:\n",
    "            parents: list of int, root nodes' ids\n",
    "        Output:\n",
    "            sub_T_nodes: set of int, all child nodes of parents and parents themselves\n",
    "        '''\n",
    "        sub_T_nodes = set()\n",
    "        child_nodes_to_parse = parents\n",
    "        while child_nodes_to_parse:\n",
    "            p = child_nodes_to_parse.pop(0)\n",
    "            sub_T_nodes.add(p)\n",
    "            child_nodes_to_parse.extend(list(self.skeleton_tree.successors(p))) # p has direct children\n",
    "        return sub_T_nodes\n",
    "    \n",
    "    def getInactiveNodes(self, former_population = 0):\n",
    "        '''\n",
    "        Input:\n",
    "            former_population: int, node number by the end of last time stamp\n",
    "        Output:\n",
    "            inactive_leaves: list of int, inactive node ids\n",
    "        '''\n",
    "        inactive_leaves = list()\n",
    "        for i,n in enumerate(self.G.nodes):\n",
    "            children = list(self.G.successors(n))\n",
    "            if not children:\n",
    "                inactive_leaves.append(i) \n",
    "            elif i < former_population and max(children)<former_population:\n",
    "                inactive_leaves.append(i)\n",
    "        return inactive_leaves\n",
    "    \n",
    "    def diffuseHeat(self, hottest_nodes, coldest_nodes, num_of_round):\n",
    "        '''\n",
    "        Compute heat diffusion over a skeleton tree\n",
    "        Input:\n",
    "            G: nx.graph.DiGraph,  loopless graph with node attribute 'tree_entropy'\n",
    "            hottest_nodes: list of int, nodes at temperature 1\n",
    "            coldest_nodes: list of int, nodes at temperature 0\n",
    "            num_of_round: int, number of steps    \n",
    "        Output: \n",
    "            Temperatures: ndarray, node temperature list after num_of_round steps \n",
    "        '''    \n",
    "       \n",
    "        adjacency = nx.to_scipy_sparse_matrix(self.G, weight = 'distance').T   \n",
    "        n = adjacency.shape[0]\n",
    "        Temperatures = 0.5 * np.ones(n, float)\n",
    "        sources = np.array(hottest_nodes)  \n",
    "        targets = np.array(coldest_nodes)\n",
    "\n",
    "        # fix source and target temperature\n",
    "        Temperatures[sources] = 1 # red\n",
    "        Temperatures[targets] = 0  # blue\n",
    "\n",
    "        # compute transition matrix\n",
    "        wgts = adjacency.dot(np.ones(n))\n",
    "        inverse_weight_matrix = sparse.diags(1 / wgts, format='csr')\n",
    "        P = inverse_weight_matrix.dot(adjacency)\n",
    "\n",
    "        \n",
    "        # heat diffusion \n",
    "        Temperatures = P.T.dot(Temperatures)\n",
    "        Temperatures = (Temperatures - min(Temperatures))/(max(Temperatures) - min(Temperatures))\n",
    "        Temperatures[sources] = 1   \n",
    "        Temperatures[targets] = 0\n",
    "        for i in range(num_of_round):\n",
    "            Temperatures = P.dot(Temperatures)   \n",
    "            # fix source and target temperature\n",
    "            Temperatures[sources] = 1   \n",
    "            Temperatures[targets] = 0    \n",
    "\n",
    "        # rescale temperature    \n",
    "        mean_T = np.mean(Temperatures)    \n",
    "        Temperatures *= self.average_temperature/mean_T    \n",
    "        return Temperatures\n",
    "    \n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $T_{struct}^t$ ---- shrink $G^{t+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_von_neumann_E_shrinked(prev_G, G, node_df):\n",
    "    '''\n",
    "    Shrink current citation graph to a graph induced by nodes in prev_G\n",
    "    Get von neumann entropy on the shrinked graph\n",
    "    Input:\n",
    "        prev_G: nx.DiGraph, citation graph by the end of last timestamp\n",
    "        G: nx.DiGraph, current citation graph\n",
    "        node_df: pd.DataFrame, columns = ['paper_id','year']\n",
    "    Output:\n",
    "        E: float, von neumann entropy of the graph shrinked from G\n",
    "    '''\n",
    "    \n",
    "    if not prev_G.number_of_nodes():\n",
    "        return 0,0\n",
    "    \n",
    "    node_df = node_df.set_index('paper_id')\n",
    "    new_edge_wgt_sum = 0\n",
    "    # shrink network\n",
    "    nx.set_edge_attributes(G, 1,'weight')\n",
    "    nodes_to_rm = set(G.nodes).difference(set(prev_G.nodes))\n",
    "    for n in nodes_to_rm:\n",
    "        parents_n = set(G.predecessors(n))\n",
    "        if len(parents_n) == 1:\n",
    "            for c in G.successors(n):\n",
    "                G.add_edge(next(iter(parents_n)), c, weight = G[n][c]['weight']/2) \n",
    "            G.remove_node(n)\n",
    "        else:\n",
    "            # more than 1 parent\n",
    "            # find all youngest ancestor nodes in prev_G\n",
    "            # add virtual edges between them, weight = 1/# youngest ancestor nodes\n",
    "            ancestors_n = parents_n\n",
    "            wgt_shared = sum([G[p][n]['weight'] for p in ancestors_n])\n",
    "            tmp = ancestors_n.intersection(nodes_to_rm)\n",
    "            while tmp:\n",
    "                tmp_ancestors = []\n",
    "                tmp_ancestors.extend([list(G.predecessors(k)) for k in tmp])\n",
    "                tmp_ancestors = list(chain.from_iterable(tmp_ancestors))  # unlist nested list\n",
    "                ancestors_n.union(set(tuple(tmp_ancestors)))\n",
    "                ancestors_n -= tmp # set difference\n",
    "                tmp = ancestors_n.intersection(nodes_to_rm)\n",
    "            num_of_ancestors = len(ancestors_n)\n",
    "            if num_of_ancestors > 1:\n",
    "                # add edge\n",
    "                ancestors_dict = dict([(i, node_df.at[i, 'year']) for i in ancestors_n])\n",
    "                for u_dict,v_dict in combinations(ancestors_dict.items(),2):\n",
    "                    if not prev_G.has_edge(u_dict[0], v_dict[0]) and not prev_G.has_edge(u_dict[0], v_dict[0]):\n",
    "                        if not G.has_edge(u_dict[0], v_dict[0]) and not G.has_edge(v_dict[0], u_dict[0]): # 取第一条边\n",
    "                            if u_dict[1] < v_dict[1]: \n",
    "                                G.add_edge(u_dict[0], v_dict[0], weight = 2*wgt_shared/num_of_ancestors/(num_of_ancestors-1))\n",
    "                            elif u_dict[1] > v_dict[1]:\n",
    "                                G.add_edge(v_dict[0], u_dict[0], weight = 2*wgt_shared/num_of_ancestors/(num_of_ancestors-1))   \n",
    "                            else: # paper on same year, bidirectional edges\n",
    "                                G.add_edge(u_dict[0], v_dict[0], weight = wgt_shared/num_of_ancestors/(num_of_ancestors-1))\n",
    "                                G.add_edge(v_dict[0], u_dict[0], weight = wgt_shared/num_of_ancestors/(num_of_ancestors-1))\n",
    "                            new_edge_wgt_sum += 2*wgt_shared/num_of_ancestors/(num_of_ancestors-1)    \n",
    "                G.remove_node(n)\n",
    "            \n",
    "     # get entropy\n",
    "    E = 0\n",
    "    for c in sorted(nx.strongly_connected_components(G), key=len, reverse=True):\n",
    "        sc_node_num = len(c)\n",
    "        if sc_node_num>1:\n",
    "            sub_G = G.subgraph(c).copy()\n",
    "            # get res\n",
    "            res = sum([wgt**2 * sub_G.in_degree(u)/sub_G.in_degree(v)/sub_G.out_degree(u)**2 \\\n",
    "                       for (u,v,wgt) in sub_G.edges.data('weight')])  #combinations(c, 2):   \n",
    "            E += 1-1/sc_node_num - res/2/sc_node_num**2\n",
    "            for u,v in combinations(sub_G.nodes,2):\n",
    "                if sub_G.has_edge(u,v) and sub_G.has_edge(v,u):\n",
    "                    E -= sub_G[u][v]['weight']*sub_G[v][u]['weight']/sub_G.in_degree(v)/sub_G.out_degree(u)\n",
    "        else:\n",
    "            # strongly connected component containing 1 node\n",
    "            # von neumann entropy = 0\n",
    "            break\n",
    "    return E, new_edge_wgt_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>reference_id</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8777697</td>\n",
       "      <td>99188113</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>498094871</td>\n",
       "      <td>99188113</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>352699142</td>\n",
       "      <td>99188113</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39453343</td>\n",
       "      <td>99188113</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>470391866</td>\n",
       "      <td>99188113</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    paper_id  reference_id  year\n",
       "0    8777697      99188113  1995\n",
       "1  498094871      99188113  1995\n",
       "2  352699142      99188113  1995\n",
       "3   39453343      99188113  1995\n",
       "4  470391866      99188113  1995"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_df = pd.read_csv(r'99188113domain_reference.csv')\n",
    "ref_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>352699142</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47465484</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34702267</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39453343</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>498094871</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    paper_id  year\n",
       "0  352699142  1993\n",
       "1   47465484  1993\n",
       "2   34702267  1993\n",
       "3   39453343  1994\n",
       "4  498094871  1994"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_df = pd.read_csv(r'99188113domain_paper.csv')\n",
    "paper_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run single-domain T evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEvolvingTemperature(ref_df, paper_df, lead_paper_id, evolve_step=1):\n",
    "    '''\n",
    "    Compute evolving node temperature based on mainly domain skeleton tree and node tree entropy\n",
    "    Visualise every evolve_step-year\n",
    "    Input: \n",
    "        ref_df: pandas Dataframe, columns = ['paper_id','reference_id','year']\n",
    "        paper_df:  pandas Dataframe, columns = ['paper_id','year']\n",
    "        lead_paper_id: int, original id of the pionneering work\n",
    "        evolve_step: interval between 2 visualization, unit: year \n",
    "    Output:\n",
    "        None\n",
    "    '''\n",
    "    domain = Domain()\n",
    "    start_year = ref_df['year'].min()\n",
    "    end_year = ref_df['year'].max()\n",
    "    T = int((end_year - start_year)/evolve_step)\n",
    "    delta = (end_year - start_year)%evolve_step \n",
    "    domain.setBirthYear(start_year)\n",
    "    \n",
    "    # record network size and average temperature for visualization\n",
    "    yr_stamps = list()\n",
    "    yr_node_number = list()\n",
    "    yr_edge_number = list()\n",
    "    yr_mass = list()\n",
    "    yr_volume = list()\n",
    "    yr_avg_growth_temperatures = list()\n",
    "    \n",
    "    von_neumann_entropies = list()\n",
    "    von_neumann_entropies_shrink = list()\n",
    "    yr_avg_struct_temperatures = list()\n",
    "    \n",
    "    is_big_graph = True if paper_df.shape[0]>5000 else False\n",
    "    \n",
    "    for t in range(T+1):\n",
    "        \n",
    "        print('round',t)\n",
    "        t3 = perf_counter()\n",
    "        \n",
    "        prev_G = deepcopy(domain.G)\n",
    "        \n",
    "        t1 = perf_counter()\n",
    "        domain.evolve(ref_df, lead_paper_id, start_year+delta+t*evolve_step, evolve_step)\n",
    "        print('Evolve domain elapsed time: {}s'.format(perf_counter() - t1))\n",
    "        \n",
    "        if t>=1:\n",
    "            # get equivalent shrinked network, remove all new nodes, add edges between old nodes\n",
    "            curr_G = deepcopy(domain.G)\n",
    "            H, delta_edge_sum = get_von_neumann_E_shrinked(prev_G, curr_G, paper_df)\n",
    "            H_prev = von_neumann_entropies[-1]\n",
    "            try:\n",
    "                struct_Temperature = delta_edge_sum/(H - H_prev) if delta_edge_sum else 0\n",
    "            except: # float division by 0 error\n",
    "                struct_Temperature = 10*delta_edge_sum\n",
    "            avg_struct_T = struct_Temperature/domain.num_of_nodes \n",
    "            domain.setStructTemperature(avg_struct_T)\n",
    "            print('old E: {o}, new_E: {n}, struct_T: {T}'.format(o=H_prev,n=H,T= avg_struct_T))\n",
    "    \n",
    "            von_neumann_entropies_shrink.append(H)\n",
    "            yr_avg_struct_temperatures.append(avg_struct_T)\n",
    "        else:\n",
    "            # first round, no struct change\n",
    "            yr_avg_struct_temperatures.append(0)\n",
    "            domain.setStructTemperature(0)\n",
    "            \n",
    "        domain.getVonNeumannEntropy()\n",
    "        von_neumann_entropies.append(domain.von_neumann_entropy)\n",
    "        \n",
    "        \n",
    "        t1 = perf_counter()\n",
    "        domain.setNodeReductionIdx()\n",
    "        print('Get node reduction index elapsed time: {}s'.format(perf_counter() - t1))\n",
    "        \n",
    "       \n",
    "        t1 = perf_counter()\n",
    "        domain.buildSkeletonTree()\n",
    "        print(\"Build skeleton tree elapsed time: {}s\".format(perf_counter() - t1))\n",
    "        \n",
    "        \n",
    "        # compute tree entropy\n",
    "        t1 = perf_counter()    \n",
    "        domain.setNodeTreeEntropy()\n",
    "        print(\"Compute tree entropy elapsed time: {}s\".format(perf_counter() - t1))\n",
    " \n",
    "  \n",
    "        # compute domain average temperature and node temperature\n",
    "        t1 = perf_counter()\n",
    "        if t == 0:    \n",
    "            domain.getAvgTemperature(is_initial = True, is_big_graph = is_big_graph)\n",
    "            domain.spreadTemperature(former_population = 0)\n",
    "        else:    \n",
    "            domain.getAvgTemperature(is_initial = False, is_big_graph = is_big_graph,\n",
    "                                                         old_avg_temperature = yr_avg_growth_temperatures[-1],\n",
    "                                                         old_V = yr_volume[-1],\n",
    "                                                         old_N = yr_mass[-1])\n",
    "            domain.spreadTemperature(former_population = yr_node_number[-1])\n",
    "        print(\"Compute average and node temperature elapsed time: {}s\".format(perf_counter() - t1))\n",
    "          \n",
    "        \n",
    "        # export node info\n",
    "        df_node_export = pd.DataFrame({'id':list(domain.G.nodes),'T': domain.node_temperature})       \n",
    "        df_node_export['tree_entropy'] = domain.node_tree_entropy\n",
    "        df_node_export.to_csv(str(lead_paper_id)+'node_'+ str(domain.evolving_until_yr)+'.csv', index = False)\n",
    "        # export edge info\n",
    "        df_edge_export = pd.DataFrame(list(domain.skeleton_tree.edges))\n",
    "        df_edge_export.columns = ['reference_id','paper_id']\n",
    "        df_edge_export.to_csv(str(lead_paper_id)+'edge_'+ str(domain.evolving_until_yr)+'.csv', index = False)\n",
    "        \n",
    "        \n",
    "        t4 = perf_counter()\n",
    "        print('total running time: {}s'.format(t4-t3))\n",
    "        print()\n",
    "        \n",
    "        yr_stamps.append(domain.evolving_until_yr)\n",
    "        yr_node_number.append(domain.num_of_nodes)\n",
    "        yr_edge_number.append(domain.num_of_edges)  \n",
    "        yr_mass.append(domain.mass)\n",
    "        yr_volume.append(domain.volume)\n",
    "        yr_avg_growth_temperatures.append(domain.average_growth_temperature)\n",
    "\n",
    "        \n",
    "    d = {'year':yr_stamps, 'node number':yr_node_number,\n",
    "         'edge number':yr_edge_number, 'mass':yr_mass, 'volume': yr_volume,\n",
    "         'T_growth_t': yr_avg_growth_temperatures,'T_struct_t': abs(np.array(yr_avg_struct_temperatures)),\n",
    "         'T_t':np.array(yr_avg_growth_temperatures)+abs(np.array(yr_avg_struct_temperatures))}    \n",
    "    df_network_evolve_info = pd.DataFrame(data=d)\n",
    "    with pd.ExcelWriter(str(lead_paper_id)+' domain stats.xlsx') as writer:\n",
    "        df_network_evolve_info.to_excel(writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0\n",
      "Evolve domain elapsed time: 0.00860419267947205s\n",
      "von neumann entropy\n",
      "2.291361239711934\n",
      "Get node reduction index elapsed time: 2.2236642273839777s\n",
      "Build skeleton tree elapsed time: 0.8759111166902862s\n",
      "Compute tree entropy elapsed time: 0.20541950243710794s\n",
      "volume:586, mass:494.41769774908636, T_growth:2.5829223433433177\n",
      "Compute average and node temperature elapsed time: 0.035238014304236565s\n",
      "total running time: 3.3738805751737604s\n",
      "\n",
      "round 1\n",
      "Evolve domain elapsed time: 0.0159661177957382s\n",
      "old E: 2.291361239711934, new_E: -4.415954206355881, struct_T: -0.008222634842834385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "von neumann entropy\n",
      "8.763838737119505\n",
      "Get node reduction index elapsed time: 51.708900355190494s\n",
      "Build skeleton tree elapsed time: 12.499493819163497s\n",
      "Compute tree entropy elapsed time: 2.77261355393955s\n",
      "volume:2235, mass:1779.6617842431435, T_growth:2.7368298243623146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute average and node temperature elapsed time: 0.3258859575104225s\n",
      "total running time: 67.48784972053387s\n",
      "\n",
      "round 2\n",
      "Evolve domain elapsed time: 0.03377007224756312s\n",
      "old E: 8.763838737119505, new_E: 7.2155948014382965, struct_T: -0.08949668063093381\n",
      "von neumann entropy\n",
      "16.418897134560595\n",
      "Get node reduction index elapsed time: 346.6668504973478s\n",
      "Build skeleton tree elapsed time: 64.14653538523163s\n",
      "Compute tree entropy elapsed time: 12.390054031410386s\n",
      "volume:4761, mass:3564.2200526686192, T_growth:2.910994690510742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute average and node temperature elapsed time: 1.5037929182639118s\n",
      "total running time: 425.29426649266225s\n",
      "\n",
      "round 3\n",
      "Evolve domain elapsed time: 0.06945449890918098s\n",
      "old E: 16.418897134560595, new_E: 15.182690365136965, struct_T: -0.13653136725976528\n",
      "von neumann entropy\n",
      "20.386706741042076\n",
      "Get node reduction index elapsed time: 1337.4071647420278s\n",
      "Build skeleton tree elapsed time: 194.6638366850109s\n",
      "Compute tree entropy elapsed time: 38.15902012134916s\n",
      "volume:8058, mass:5785.872129731568, T_growth:3.035052255184996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute average and node temperature elapsed time: 4.3217416570082605s\n",
      "total running time: 1576.0383600798748s\n",
      "\n",
      "round 4\n",
      "Evolve domain elapsed time: 0.1346931161874636s\n",
      "old E: 20.386706741042076, new_E: 33.96737163060811, struct_T: 0.011684745727391982\n",
      "von neumann entropy\n",
      "24.014021555856893\n",
      "Get node reduction index elapsed time: 4951.16711548857s\n",
      "Build skeleton tree elapsed time: 400.4496229296574s\n",
      "Compute tree entropy elapsed time: 76.38764954020553s\n",
      "volume:11202, mass:7789.448917998839, T_growth:3.1339825630751776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute average and node temperature elapsed time: 8.892258060193853s\n",
      "total running time: 5439.659167691311s\n",
      "\n",
      "round 5\n",
      "Evolve domain elapsed time: 0.22855924819305073s\n",
      "old E: 24.014021555856893, new_E: 49.578858756780186, struct_T: 0.005061165978015126\n",
      "von neumann entropy\n",
      "27.253604889190225\n",
      "Get node reduction index elapsed time: 8037.761105917854s\n",
      "Build skeleton tree elapsed time: 659.6993603185947s\n",
      "Compute tree entropy elapsed time: 119.81500333398799s\n",
      "volume:13788, mass:9374.213160838674, T_growth:3.2053406485253233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute average and node temperature elapsed time: 16.069393848887557s\n",
      "total running time: 8837.240443125971s\n",
      "\n",
      "round 6\n",
      "Evolve domain elapsed time: 0.29649467566923704s\n",
      "old E: 27.253604889190225, new_E: 6.7774620693316905, struct_T: -0.00427444415316323\n",
      "von neumann entropy\n",
      "28.26054933363467\n",
      "Get node reduction index elapsed time: 11438.462741670057s\n",
      "Build skeleton tree elapsed time: 924.6808624150763s\n",
      "Compute tree entropy elapsed time: 161.51702837468838s\n",
      "volume:15763, mass:10605.174812853717, T_growth:3.2391330318830933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute average and node temperature elapsed time: 30.13359295303235s\n",
      "total running time: 12559.760697588068s\n",
      "\n",
      "round 7\n",
      "Evolve domain elapsed time: 0.2671897848449589s\n",
      "old E: 28.26054933363467, new_E: -16.48999816017973, struct_T: -0.0010508305097180152\n",
      "von neumann entropy\n",
      "28.76054933363467\n",
      "Get node reduction index elapsed time: 14237.12583327662s\n",
      "Build skeleton tree elapsed time: 1116.6680800707181s\n",
      "Compute tree entropy elapsed time: 200.4992268885544s\n",
      "volume:16927, mass:11352.527141339822, T_growth:3.2493402213721305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute average and node temperature elapsed time: 42.23266546613013s\n",
      "total running time: 15602.421632592755s\n",
      "\n",
      "round 8\n",
      "Evolve domain elapsed time: 0.34853345077863196s\n",
      "old E: 28.76054933363467, new_E: -56.13302849005679, struct_T: -5.531978134770794e-05\n",
      "von neumann entropy\n",
      "28.76054933363467\n",
      "Get node reduction index elapsed time: 14346.428840071887s\n",
      "Build skeleton tree elapsed time: 1117.3819939258246s\n",
      "Compute tree entropy elapsed time: 219.89368509875203s\n",
      "volume:17046, mass:11431.177148790819, T_growth:3.2496700673032475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute average and node temperature elapsed time: 41.69318706335616s\n",
      "total running time: 15733.072351947834s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# call function\n",
    "pioneer_id = 99188113\n",
    "getEvolvingTemperature(ref_df, paper_df, pioneer_id, evolve_step = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## domain group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DomainGroup(Domain):\n",
    "    '''\n",
    "    A group of domains with similar research interests. Each domain is an object of Class Domain.\n",
    "    '''\n",
    "    def __init__(self, num, T):\n",
    "        self.domain_number = 0\n",
    "        self.domains = list()\n",
    "        self.domain_ages = np.zeros(num, dtype = int)\n",
    "\n",
    "        self.domain_avg_temperatures = np.zeros([T, num])\n",
    "        self.domains_helped = list() \n",
    "        self.total_rounds = T\n",
    "        self.current_round = 0\n",
    "    \n",
    "    def initializeDomains(self, start_yrs):\n",
    "        # create domains\n",
    "        for yr in start_yrs:\n",
    "            d = Domain()\n",
    "            d.setBirthYear(yr)\n",
    "            self.domains.append(d)\n",
    "        \n",
    "    def setDomainAvgTemperatures(self, t, domain_idx, is_born = True):\n",
    "        if not is_born or self.domains[domain_idx].evolving_until_yr == self.domains[domain_idx].birth_yr:\n",
    "            self.domain_avg_temperatures[t, domain_idx] = -1\n",
    "        else:\n",
    "            self.domain_avg_temperatures[t, domain_idx] = self.domains[domain_idx].average_temperature\n",
    "        \n",
    "    def updateDomainAges(self):\n",
    "        self.domain_ages = np.array([d.evolving_until_yr - d.birth_yr for d in self.domains])\n",
    "        self.domain_ages = np.where(self.domain_ages < 0, 0, self.domain_ages)\n",
    "    \n",
    "    def decideHelpWho(self):\n",
    "        '''\n",
    "        Identify domain(s) with a declining knowledge temperature during the last evolution period\n",
    "        Output:\n",
    "            int, index of the stagnating domain(s) in self.domains\n",
    "        '''\n",
    "        recent_avg_temperature_growth = np.true_divide(self.domain_avg_temperatures[self.current_round,:],\\\n",
    "                                                       self.domain_avg_temperatures[self.current_round-1,:]) \n",
    "        \n",
    "        if min(recent_avg_temperature_growth)>1:\n",
    "             # both/all grow, no need to help\n",
    "            return np.array([])\n",
    "        else:\n",
    "            return np.argwhere(abs(recent_avg_temperature_growth)<1).flatten()\n",
    "        \n",
    "   \n",
    "    def adjustAvgTemp(self, target_domain_idx, t):\n",
    "        '''\n",
    "        Adjust the knowledge temperature of the stagnating domain(s)\n",
    "        Input: \n",
    "            target_domain_idx: int, index of the stagnating domain(s) in self.domains\n",
    "        Output:\n",
    "            energy_to_spare: float, the amount of energy to be exchanged during forest helping \n",
    "        '''\n",
    "        # get domain average temperatures before average temperature rescaling        \n",
    "        age_sum = np.sum(self.domain_ages)\n",
    "        \n",
    "        print(\"domain_to_help\", target_domain_idx)\n",
    "        print(\"current avg_T\")\n",
    "        print(self.domain_avg_temperatures[t])\n",
    "        \n",
    "        # all those with a rising knowledge temperature help the rest\n",
    "        energy_to_spare = 0\n",
    "        for idx, d in enumerate(self.domains):\n",
    "            if idx not in target_domain_idx:\n",
    "                energy_to_spare += d.num_of_nodes/(1+age_sum)*self.domain_avg_temperatures[t][idx]\n",
    "        return energy_to_spare        \n",
    "   \n",
    "    def updateDomainInHelp(self, target_domain_idx, t, delta_U):\n",
    "        '''\n",
    "        Perform forest helping\n",
    "        Update knowledge temperature of every domain after energy transfer\n",
    "        Input:\n",
    "            target_domain_idx: list of int, index of domain(s) receiving energy\n",
    "            t: int, current timestamp\n",
    "            delta_U: float, the total amount of energy given to domain(s) in need of help\n",
    "        '''\n",
    "        # get knowledge temperature increment for domain(s) in need of help\n",
    "        delta_T = delta_U/sum([self.domains[d].num_of_nodes for d in target_domain_idx])\n",
    "        \n",
    "        # update domain knowledge temperature\n",
    "        for i, domain in enumerate(self.domains):\n",
    "            if i in target_domain_idx:\n",
    "                new_avg_T = domain.average_temperature + delta_T\n",
    "            else:\n",
    "                new_avg_T = domain.average_temperature * sum(self.domain_ages)/(1+sum(self.domain_ages))\n",
    "            domain.node_temperature *= (new_avg_T/domain.average_temperature) \n",
    "            domain.average_struct_temperature *= (new_avg_T/domain.average_temperature)\n",
    "            domain.average_growth_temperature *= (new_avg_T/domain.average_temperature)\n",
    "            domain.average_temperature = new_avg_T\n",
    "       \n",
    "        \n",
    "    \n",
    "    def updateDomainGroupRecord(self, target_domain_idx = None, t = None):\n",
    "        '''\n",
    "        Update parameters after forest helping\n",
    "        Input:\n",
    "            target_domain_idx: list of int, domain(s) receiving help in this round. [] means no helping \n",
    "            t: int, current timestamp\n",
    "        '''\n",
    "        self.current_round += 1\n",
    "        self.domain_number = len(np.nonzero(self.domain_ages)[0])\n",
    "        if target_domain_idx:\n",
    "            for i, domain in enumerate(self.domains):\n",
    "                self.domain_avg_temperatures[t, i] = domain.average_temperature if domain.average_temperature>0 else -1\n",
    "            self.domains_helped.append(target_domain_idx)\n",
    "            print(\"updateDomainGroupRecord\")\n",
    "            print(self.domain_avg_temperatures)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run multiple domains T evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEvolvingTemperatureForest(df_ref_list, df_paper_list, lead_paper_ids, evolve_step=1):\n",
    "    '''\n",
    "    Compute knowledge temperatures for domain groups after forest helping mechanism\n",
    "    Input: \n",
    "        df_ref_list: pd.Dataframe, columns = ['paper_id','reference_id','year'], each df is a domain\n",
    "        df_paper_list: pd.Dataframe, columns = ['paper_id','year'], each df is a domain\n",
    "        lead_paper_ids: list of int, original ids of the pionneering work\n",
    "        evolve_step: int, evolving window (in year)\n",
    "    Output:\n",
    "        None\n",
    "    '''\n",
    "    # initialize domain group\n",
    "    N = len(df_ref_list)\n",
    "    start_years = [df['year'].min() for df in df_ref_list]\n",
    "    end_years = [df['year'].max() for df in df_ref_list]\n",
    "    domain_rank = np.argsort(start_years)\n",
    "    ordered_df_ref_list = list()\n",
    "    ordered_df_paper_list = list()\n",
    "    ordered_lead_paper_ids = list()\n",
    "    for i in range(N):\n",
    "        old_idx = np.argwhere(domain_rank == i).flatten()[0]\n",
    "        ordered_df_ref_list.append(df_ref_list[old_idx])\n",
    "        ordered_df_paper_list.append(df_paper_list[old_idx])\n",
    "        ordered_lead_paper_ids.append(lead_paper_ids[old_idx])\n",
    "    T = int((max(end_years) - min(start_years))/evolve_step)\n",
    "    delta = (max(end_years) - min(start_years))%evolve_step  # the beginning period where there's only one domain \n",
    "    \n",
    "    # initialize domains\n",
    "    domain_group = DomainGroup(N, T+1)\n",
    "    domain_group.initializeDomains(sorted(start_years))\n",
    "    \n",
    "    # judge if big graph, for T_growth_t\n",
    "    are_big_graphs = list([True if df.shape[0]>5000 else False for df in ordered_df_paper_list])\n",
    "    \n",
    "    # record network size and average temperature for visualization\n",
    "    yr_stamps = list()\n",
    "    yr_node_number = np.zeros([T+1,N], dtype = int)\n",
    "    yr_edge_number = np.zeros([T+1,N], dtype = int)\n",
    "    yr_mass =  np.zeros([T+1,N])\n",
    "    yr_volume = np.zeros([T+1,N])\n",
    "    von_neumann_entropies = np.zeros([T+1,N])\n",
    "    von_neumann_entropies_shrink = np.zeros([T,N])\n",
    "    yr_avg_temperature = np.zeros([T+1,N])\n",
    "    \n",
    "    current_yr = min(start_years)+delta\n",
    "    \n",
    "    prev_avg_growth_temperature = np.zeros(N)\n",
    "    \n",
    "    for t in range(T+1):\n",
    "        \n",
    "        print('round',t)\n",
    "        t3 = perf_counter()\n",
    "        \n",
    "        print('Current year', current_yr)\n",
    "        \n",
    "        t1 = perf_counter()\n",
    "        for domain_idx, (domain, lead_paper_id, df, paper_df,is_big_graph) in enumerate(zip(domain_group.domains,\n",
    "                                                                                   ordered_lead_paper_ids, \n",
    "                                                                                   ordered_df_ref_list,\n",
    "                                                                                   ordered_df_paper_list,\n",
    "                                                                                   are_big_graphs)):\n",
    "            \n",
    "            if domain.birth_yr >= current_yr+evolve_step:\n",
    "                # not born by the end of this round\n",
    "                domain_group.setDomainAvgTemperatures(t, domain_idx, is_born = False)\n",
    "                continue    \n",
    "            \n",
    "            prev_G = deepcopy(domain.G)\n",
    "                \n",
    "            domain.evolve(df, lead_paper_id, current_yr, evolve_step)\n",
    "            \n",
    "            if prev_G.number_of_nodes():\n",
    "                # get equivalent shrinked network, remove all new nodes, add edges between old nodes\n",
    "                curr_G = deepcopy(domain.G)\n",
    "                H, delta_edge_sum = get_von_neumann_E_shrinked(prev_G, curr_G, paper_df)\n",
    "                H_prev = von_neumann_entropies[t-1, domain_idx]\n",
    "                try:\n",
    "                    struct_Temperature = delta_edge_sum/(H - H_prev) if delta_edge_sum else 0\n",
    "                except: # float division by 0 error\n",
    "                    struct_Temperature = 10*delta_edge_sum  \n",
    "                avg_struct_T = struct_Temperature/domain.num_of_nodes \n",
    "                domain.setStructTemperature(avg_struct_T)\n",
    "                von_neumann_entropies_shrink[t-1, domain_idx] = H\n",
    "            else:\n",
    "                # first round, no struct change\n",
    "                domain.setStructTemperature(0)\n",
    "            \n",
    "            domain.getVonNeumannEntropy()\n",
    "            von_neumann_entropies[t, domain_idx] = domain.von_neumann_entropy\n",
    "       \n",
    "            domain.setNodeReductionIdx()\n",
    "          \n",
    "            domain.buildSkeletonTree()\n",
    "        \n",
    "            domain.setNodeTreeEntropy()\n",
    "\n",
    "            ## compute domain average temperature and node temperature\n",
    "            if prev_G.number_of_nodes() == 0:    \n",
    "                domain.getAvgTemperature(is_initial = True, is_big_graph = is_big_graph)\n",
    "                domain.spreadTemperature(former_population = 0)\n",
    "            else:    \n",
    "                domain.getAvgTemperature(is_initial = False, is_big_graph = is_big_graph,\n",
    "                                         old_avg_temperature = prev_avg_growth_temperature[domain_idx],\n",
    "                                         old_V = yr_volume[t-1, domain_idx],\n",
    "                                         old_N = yr_mass[t-1, domain_idx])\n",
    "                domain.spreadTemperature(former_population = yr_node_number[t-1, domain_idx])\n",
    "            \n",
    "            # update group avg temperature\n",
    "            domain_group.setDomainAvgTemperatures(t, domain_idx)\n",
    "                \n",
    "        print(\"Evolve domain group: {}s\".format(perf_counter() - t1))\n",
    "        \n",
    "        \n",
    "        print(\"avg_T before adjustment: \")    \n",
    "        print([d.average_temperature for d in domain_group.domains])\n",
    "        \n",
    "        print(\"avg_struct_T:\")\n",
    "        print([d.average_struct_temperature for d in domain_group.domains])\n",
    "        \n",
    "        domain_group.updateDomainAges()\n",
    "        print(\"domain ages:\", domain_group.domain_ages)\n",
    "        \n",
    "        if domain_group.domain_number >= 2:\n",
    "            # forest helping mechanism\n",
    "            t1 = perf_counter()\n",
    "            domain_to_help = domain_group.decideHelpWho()\n",
    "            print(\"domain_to_help\", domain_to_help)\n",
    "            if len(list(domain_to_help)):\n",
    "                energy_to_share = domain_group.adjustAvgTemp(domain_to_help, t) \n",
    "                domain_group.updateDomainInHelp(domain_to_help, t, energy_to_share)\n",
    "            domain_group.updateDomainGroupRecord(list(domain_to_help), t)\n",
    "            print(\"Forest helping: {}s\".format(perf_counter() - t1))\n",
    "        else:\n",
    "            domain_group.updateDomainGroupRecord()\n",
    "            \n",
    "        # output domain group evolution after forest helping  \n",
    "        for i, (domain, lead_paper_id) in enumerate(zip(domain_group.domains, ordered_lead_paper_ids)):\n",
    "#             # export node info\n",
    "#             df_node_export = pd.DataFrame({'id':list(domain.G.nodes),'T': domain.node_temperature})       \n",
    "#             df_node_export['tree_entropy'] = domain.node_tree_entropy\n",
    "#             df_node_export.to_csv(str(lead_paper_id)+'node_'+str(t)+'_'+ str(domain.evolving_until_yr)+'.csv', index = False)\n",
    "#             # export edge info\n",
    "#             df_edge_export = pd.DataFrame(list(domain.skeleton_tree.edges))\n",
    "#             df_edge_export.columns = ['reference_id','paper_id']\n",
    "#             df_edge_export.to_csv(str(lead_paper_id)+'edge_'+str(t)+'_'+ str(domain.evolving_until_yr)+'.csv', index = False)\n",
    "            \n",
    "            yr_node_number[t, i] = domain.num_of_nodes\n",
    "            yr_edge_number[t, i] = domain.num_of_edges\n",
    "            yr_mass[t, i] = domain.mass\n",
    "            yr_volume[t, i] = domain.volume\n",
    "            yr_avg_temperature[t, i] = domain.average_temperature\n",
    "            prev_avg_growth_temperature[i] = domain.average_growth_temperature \n",
    "        \n",
    "        yr_stamps.append(current_yr+evolve_step-1)\n",
    "        current_yr += evolve_step\n",
    "        \n",
    "        t4 = perf_counter()\n",
    "        print('total running time: {}s'.format(t4-t3))\n",
    "        print()\n",
    "        \n",
    "    \n",
    "    # output stats for each domain\n",
    "    for i, (domain, pioneer_id) in enumerate(zip(domain_group.domains, ordered_lead_paper_ids)):\n",
    "        d = {'year':yr_stamps, 'node number':yr_node_number[:,i],\n",
    "             'edge number':yr_edge_number[:,i], 'mass':yr_mass[:,i], 'volume': yr_volume[:,i],\n",
    "             'T_t forest':yr_avg_temperature[:,i]}    \n",
    "        df_network_evolve_info = pd.DataFrame(data=d)\n",
    "        with pd.ExcelWriter(str(pioneer_id)+' domain stats.xlsx') as writer:\n",
    "            df_network_evolve_info.to_excel(writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0\n",
      "Current year 2004\n",
      "von neumann entropy\n",
      "0\n",
      "volume:25, mass:16.203907793629746, T_growth:3.2970884071966475\n",
      "Evolve domain group: 0.02647584947408177s\n",
      "avg_T before adjustment: \n",
      "[3.2970884071966475, 0, 0]\n",
      "avg_struct_T:\n",
      "[0, 0, 0]\n",
      "domain ages: [2 0 0]\n",
      "total running time: 0.02750337366887834s\n",
      "\n",
      "round 1\n",
      "Current year 2006\n",
      "von neumann entropy\n",
      "0.7373611111111111\n",
      "volume:61, mass:38.06798740994441, T_growth:3.424366698141683\n",
      "Evolve domain group: 0.06947389281413052s\n",
      "avg_T before adjustment: \n",
      "[3.5748757942930434, 0, 0]\n",
      "avg_struct_T:\n",
      "[0.15050909615136024, 0, 0]\n",
      "domain ages: [4 0 0]\n",
      "total running time: 0.06972072429198306s\n",
      "\n",
      "round 2\n",
      "Current year 2008\n",
      "von neumann entropy\n",
      "0.7373611111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n",
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume:103, mass:64.2491622816236, T_growth:3.4259427565815264\n",
      "von neumann entropy\n",
      "0.6861979166666666\n",
      "volume:24, mass:20.88296054221835, T_growth:35.06597213638032\n",
      "Evolve domain group: 0.23404807501356117s\n",
      "avg_T before adjustment: \n",
      "[3.576511626524099, 35.06597213638032, 0]\n",
      "avg_struct_T:\n",
      "[0.15056886994257238, 0, 0]\n",
      "domain ages: [6 1 0]\n",
      "total running time: 0.2342578817770118s\n",
      "\n",
      "round 3\n",
      "Current year 2010\n",
      "von neumann entropy\n",
      "0.9873611111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n",
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume:173, mass:96.95903094402787, T_growth:3.813012102544939\n",
      "von neumann entropy\n",
      "0.9361979166666666\n",
      "volume:113, mass:83.92659329911885, T_growth:41.081430539254875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n",
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evolve domain group: 0.6888022784696659s\n",
      "avg_T before adjustment: \n",
      "[3.9137335818495114, 41.19870907827267, 0]\n",
      "avg_struct_T:\n",
      "[0.10072147930457236, -0.1172785390177931, 0]\n",
      "domain ages: [8 3 0]\n",
      "Decide help who\n",
      "[ 3.91373358 41.19870908 -1.        ]\n",
      "[ 3.57651163 35.06597214 -1.        ]\n",
      "[1.09428795 1.1748914  1.        ]\n",
      "domain_to_help []\n",
      "Forest helping: 0.0009654636814957485s\n",
      "total running time: 0.6905748810822843s\n",
      "\n",
      "round 4\n",
      "Current year 2012\n",
      "von neumann entropy\n",
      "1.4943055555555556\n",
      "volume:341, mass:170.71005666297856, T_growth:4.268798147096627\n",
      "von neumann entropy\n",
      "1.4361979166666665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume:291, mass:172.36829219371072, T_growth:51.51127739936491\n",
      "von neumann entropy\n",
      "0\n",
      "volume:29, mass:23.5, T_growth:1.977882043082873\n",
      "Evolve domain group: 3.7442296971421456s\n",
      "avg_T before adjustment: \n",
      "[4.3699869781853256, 52.043236201549696, 1.977882043082873]\n",
      "avg_struct_T:\n",
      "[0.10118883108869857, 0.5319588021847915, 0]\n",
      "domain ages: [10  5  0]\n",
      "Decide help who\n",
      "[ 4.36998698 52.0432362  -1.        ]\n",
      "[ 3.91373358 41.19870908 -1.        ]\n",
      "[1.11657753 1.26322493 1.        ]\n",
      "domain_to_help []\n",
      "Forest helping: 0.0004442966601345688s\n",
      "total running time: 3.7450251997361192s\n",
      "\n",
      "round 5\n",
      "Current year 2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n",
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "von neumann entropy\n",
      "2.4943055555555556\n",
      "volume:1050, mass:483.01618713129733, T_growth:4.645558791535432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "von neumann entropy\n",
      "1.9361979166666665\n",
      "volume:889, mass:441.7800136806248, T_growth:61.399156692973726\n",
      "von neumann entropy\n",
      "2.0555555555555554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume:1197, mass:660.2316384373203, T_growth:2.9058157299409495\n",
      "Evolve domain group: 61.97128891518514s\n",
      "avg_T before adjustment: \n",
      "[4.730542110901751, 61.78963036932579, 2.9671404666677326]\n",
      "avg_struct_T:\n",
      "[0.08498331936631819, 0.39047367635206887, 0.061324736726782916]\n",
      "domain ages: [12  7  2]\n",
      "Decide help who\n",
      "[ 4.73054211 61.78963037  2.96714047]\n",
      "[ 4.36998698 52.0432362  -1.        ]\n",
      "[ 1.08250714  1.18727494 -2.96714047]\n",
      "domain_to_help []\n",
      "Forest helping: 0.0004460597410798073s\n",
      "total running time: 61.97358762146905s\n",
      "\n",
      "round 6\n",
      "Current year 2016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "von neumann entropy\n",
      "3.8554166666666667\n",
      "volume:2179, mass:1090.1620661411712, T_growth:4.27146164597828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "von neumann entropy\n",
      "2.936197916666667\n",
      "volume:1766, mass:926.1557475114307, T_growth:58.179955213944396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "von neumann entropy\n",
      "7.595833333333333\n",
      "volume:4136, mass:2159.2751105387424, T_growth:3.0700312999073898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evolve domain group: 542.130343240322s\n",
      "avg_T before adjustment: \n",
      "[4.500288680736277, 58.35840263775217, 3.3376831423735047]\n",
      "avg_struct_T:\n",
      "[0.2288270347579973, 0.17844742380777204, -0.26765184246611484]\n",
      "domain ages: [14  9  4]\n",
      "Decide help who\n",
      "[ 4.50028868 58.35840264  3.33768314]\n",
      "[ 4.73054211 61.78963037  2.96714047]\n",
      "[0.95132621 0.9444692  1.12488208]\n",
      "domain_to_help [0 1]\n",
      "adjustAvgTemp\n",
      "domain_to_help [0 1]\n",
      "current avg_T\n",
      "[ 4.50028868 58.35840264  3.33768314]\n",
      "updateDomainGroupRecord\n",
      "[[ 3.29708841 -1.         -1.        ]\n",
      " [ 3.57487579 -1.         -1.        ]\n",
      " [ 3.57651163 35.06597214 -1.        ]\n",
      " [ 3.91373358 41.19870908 -1.        ]\n",
      " [ 4.36998698 52.0432362  -1.        ]\n",
      " [ 4.73054211 61.78963037  2.96714047]\n",
      " [ 4.62526295 58.4833769   3.21848017]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]]\n",
      "Forest helping: 0.002053285264992155s\n",
      "total running time: 542.132827775451s\n",
      "\n",
      "round 7\n",
      "Current year 2018\n",
      "von neumann entropy\n",
      "4.605416666666667\n",
      "volume:3157, mass:1648.7683174385566, T_growth:4.2055359460742086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "von neumann entropy\n",
      "3.436197916666667\n",
      "volume:2640, mass:1441.2875651602556, T_growth:56.007868120593486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "von neumann entropy\n",
      "11.047222222222222\n",
      "volume:7736, mass:3999.5846126825813, T_growth:2.9893554429096643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evolve domain group: 2150.1356970150664s\n",
      "avg_T before adjustment: \n",
      "[4.258736206131108, 56.09520822816617, 3.5192992395154974]\n",
      "avg_struct_T:\n",
      "[0.05320026005689892, 0.08734010757268709, -0.5299437966058331]\n",
      "domain ages: [16 11  6]\n",
      "Decide help who\n",
      "[ 4.25873621 56.09520823  3.51929924]\n",
      "[ 4.62526295 58.4833769   3.21848017]\n",
      "[0.92075548 0.959165   1.09346619]\n",
      "domain_to_help [0 1]\n",
      "adjustAvgTemp\n",
      "domain_to_help [0 1]\n",
      "current avg_T\n",
      "[ 4.25873621 56.09520823  3.51929924]\n",
      "updateDomainGroupRecord\n",
      "[[ 3.29708841 -1.         -1.        ]\n",
      " [ 3.57487579 -1.         -1.        ]\n",
      " [ 3.57651163 35.06597214 -1.        ]\n",
      " [ 3.91373358 41.19870908 -1.        ]\n",
      " [ 4.36998698 52.0432362  -1.        ]\n",
      " [ 4.73054211 61.78963037  2.96714047]\n",
      " [ 4.62526295 58.4833769   3.21848017]\n",
      " [ 4.39686698 56.233339    3.41579044]\n",
      " [ 0.          0.          0.        ]]\n",
      "Forest helping: 0.003033558852621354s\n",
      "total running time: 2150.1403589564434s\n",
      "\n",
      "round 8\n",
      "Current year 2020\n",
      "von neumann entropy\n",
      "4.605416666666667\n",
      "volume:3265, mass:1711.8252557885594, T_growth:4.325066047530641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "von neumann entropy\n",
      "3.436197916666667\n",
      "volume:2733, mass:1503.842150949534, T_growth:55.70590578520275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "von neumann entropy\n",
      "11.047222222222222\n",
      "volume:8133, mass:4199.586403644498, T_growth:2.905061018978325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ldr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:371: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evolve domain group: 2481.8792468678002s\n",
      "avg_T before adjustment: \n",
      "[4.3404921576452065, 55.71546360465732, 2.92030131434172]\n",
      "avg_struct_T:\n",
      "[0.015426110114565277, 0.00955781945457241, 0.015240295363394874]\n",
      "domain ages: [17 12  7]\n",
      "Decide help who\n",
      "[ 4.34049216 55.7154636   2.92030131]\n",
      "[ 4.39686698 56.233339    3.41579044]\n",
      "[0.98717841 0.9907906  0.85494159]\n",
      "domain_to_help [0 1 2]\n",
      "adjustAvgTemp\n",
      "domain_to_help [0 1 2]\n",
      "current avg_T\n",
      "[ 4.34049216 55.7154636   2.92030131]\n",
      "updateDomainGroupRecord\n",
      "[[ 3.29708841 -1.         -1.        ]\n",
      " [ 3.57487579 -1.         -1.        ]\n",
      " [ 3.57651163 35.06597214 -1.        ]\n",
      " [ 3.91373358 41.19870908 -1.        ]\n",
      " [ 4.36998698 52.0432362  -1.        ]\n",
      " [ 4.73054211 61.78963037  2.96714047]\n",
      " [ 4.62526295 58.4833769   3.21848017]\n",
      " [ 4.39686698 56.233339    3.41579044]\n",
      " [ 4.34049216 55.7154636   2.92030131]]\n",
      "Forest helping: 0.002019786712480709s\n",
      "total running time: 2481.882971202169s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# call function\n",
    "\n",
    "# wireless networks\n",
    "# ref_df1 = pd.read_csv(r'wireless networks forest/62270017domain_reference.csv')\n",
    "# ref_df2 = pd.read_csv(r'wireless networks forest/438420345domain_reference.csv')\n",
    "# paper_df1 = pd.read_csv(r'wireless networks forest/62270017domain_paper.csv')\n",
    "# paper_df2 = pd.read_csv(r'wireless networks forest/438420345domain_paper.csv')\n",
    "\n",
    "# GRU LSTM\n",
    "# ref_df1 = pd.read_csv(r'RNN memory layer forest/168338164domain_reference.csv')\n",
    "# ref_df2 = pd.read_csv(r'RNN memory layer forest/56158074domain_reference.csv')\n",
    "# paper_df1 = pd.read_csv(r'RNN memory layer forest/168338164domain_paper.csv')\n",
    "# paper_df2 = pd.read_csv(r'RNN memory layer forest/56158074domain_paper.csv')\n",
    "\n",
    "# RNN word embeddings\n",
    "ref_df1 = pd.read_csv(r'word embedding forest/223688399domain_reference.csv')\n",
    "ref_df2 = pd.read_csv(r'word embedding forest/256500874domain_reference.csv')\n",
    "ref_df3 = pd.read_csv(r'word embedding forest/372720438domain_reference.csv')\n",
    "paper_df1 = pd.read_csv(r'word embedding forest/223688399domain_paper.csv')\n",
    "paper_df2 = pd.read_csv(r'word embedding forest/256500874domain_paper.csv')\n",
    "paper_df3 = pd.read_csv(r'word embedding forest/372720438domain_paper.csv')\n",
    "\n",
    "df_ref_list = [ref_df1, ref_df2, ref_df3]\n",
    "df_paper_list = [paper_df1, paper_df2, paper_df3]\n",
    "lead_paper_ids = [223688399, 256500874, 372720438]\n",
    "getEvolvingTemperatureForest(df_ref_list, df_paper_list, lead_paper_ids, evolve_step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
